---
title: Corpus Analysis
authors: Filip Krikava, Heather Miller and Jan Vitek
output:
  html_document:
    code_folding: hide
    theme: united
    toc: true
    toc_float: true
params:
  corpus_dir: /var/lib/scala/corpora/github
  corpus_url: http://prl1.ele.fit.cvut.cz:8149
  lib_dir: ../inc
  report_name: implicits-analysis
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
source(file.path(params$lib_dir, "setup.R"))
```

```{r}
JOIN_BY <- c("mid", "declaration_id")
```

## Introduction

The notebook contains the automated analysis of the results of the implicits extraction pipeline.
Some of the analysis in the paper was done manually by inspecting the data presented in the tables rendered by this script.

## Data Definition

The following is the summary of the data exported from the corpus.

### Implicit Declarations

The `r IMPLICIT_DECLARATIONS_F` file contains all the implicit declarations, including all defs with implicit parameters.
It contains the following columns:

- `project_id` (chr): project name as `github-user-name--github-repository-name`
- `module_id` (chr): module id as `project_id::group_id:artifact_id:version:platform`
- `group_id` (chr): organization name
- `artifact_id` (chr): artifact name
- `version` (chr): version
- `kind` (chr): one of `DEF`, `CLASS`, `VAL`, `VAR`, `OBJECT`, `MACRO`, `PARAMETER`
- `declaration_id` (chr): fully qualified name of the declaration
- `name` (chr): just the declaration name
- `location_path` (chr): the folder or jar file in which it is defined
- `location_uri` (chr): the file name within that folder or jar file
- `location_pos` (chr): `start_line:start_coulmn` in case it was available or `NA`
- `location_scope` (chr): a `;`-separated tags:
    - `compile` - in a compile scope
    - `test` - in a test scope
    - `managed` - in an SBT managed directory (i.e. a generated source)
    - `dependency` - in a dependency in respect to the module (group_id:artifact_id)
    - `transitive` - in a transitive depenency
- `compilation_unit` (chr): the fully qualified name of the enclosing compilation unit
- `def_group_id` (chr): the organization name of the library where the decalration originates
- `def_artifact_id` (chr): the artifact name of the library where the decalration originates
- `def_version` (chr): the version of the library where the decalration originates
- `is_implicit` (lgl): does it come with the `implicit` keyword?
- `is_companion` (lgl): is it the `implicit def` generated for an `implicit class`?
- `access` (chr): access modifiers (e.g. `PUBLIC`, `PRIVATE`, ...)
- `annotations` (char): a `;`-separated list of attached annotation 
- `num_type_parameters` (int): number of type parameters it defines
- `num_parameter_lists` (int): number of parameter lists
- `num_parameters` (int): total number of parameters
- `num_implicit_parameters` (int): number of implicit parameters
- `github_url` (chr): a link to github if available to see the actual code

It was created by [ImplicitDeclarationExporter.scala](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ 	ImplicitDeclarationExporter.scala).

### Implicit Call Sites

The `r IMPLICIT_CALLSITES_F` file contains all the callsites involving implicits.
It contains the following columns:

- `project_id` (chr): project name as `github-user-name--github-repository-name`
- `module_id` (chr): module id as `project_id::group_id:artifact_id:version:platform`
- `group_id` (chr): organization name
- `artifact_id` (chr): artifact name
- `version` (chr): version
- `callsite_id` (int): an id of a call site which is unique within a module
- `parent_id` (int): an id to a parent call site in the case this one is nested or `NA`
- `code` (chr): an up to 50 chars snippet of the call site code
- `nested_calls` (chr): `;`-separated list of call nested call sites
- `arguments` (chr): `;`-separated list of arguments declaration ids
- `declaration_id` (chr): a declaration id of the function/method
- `local` (chr): is it `project`-local, `module`-local or `NA`
- `location_path` (chr): the folder or jar file in which it is defined
- `location_uri` (chr): the file name within that folder or jar file
- `location_pos` (chr): `start_line:start_coulmn` in case it was available or `NA`
- `location_scope` (chr): a `,`-separated tags:
    - `compile` - in a compile scope
    - `test` - in a test scope
    - `managed` - in an SBT managed directory (i.e. a generated source)
    - `dependency` - in a dependency in respect to the module (group_id:artifact_id)
    - `transitive` - in a transitive depenency
- `num_type_parameters` (int): number of type parameters it has
- `num_implicit_parameters` (int): number of implicit parameters
- `github_url` (chr): a link to github if available to see the actual code

It was created by [ImplicitCallSitesExporter.scala](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ 	ImplicitCallSitesExporter.scala).

### Implicit Conversions

The `r IMPLICIT_CONVERSIONS_F` file contains all the callsites involving implicits.
It contains the following columns:

- `project_id` (chr): project name as `github-user-name--github-repository-name`
- `module_id` (chr): module id as `project_id::group_id:artifact_id:version:platform`
- `declaration_id` (chr): a declaration id of the implicit conversion
- `from` (chr): a declaration id of the from parameter
- `from_groupId` (chr): organization name of the library where from is defined
- `from_artifactId` (chr): artifact name of the library where from is defined
- `from_version` (chr): version of the library where from is defined
- `from_scope` (chr): a `,`-separated tags:
    - `compile` - in a compile scope
    - `test` - in a test scope
    - `managed` - in an SBT managed directory (i.e. a generated source)
    - `dependency` - in a dependency in respect to the module (group_id:artifact_id)
    - `transitive` - in a transitive depenency
- `from_compilation_unit` (chr): the fully qualified name of the enclosing compilation unit of the to parameter
- `from_language` (chr): either `SCALA` or `JAVA`
- `to` (chr): a declaration id of the to parameter
- `to_groupId` (chr): organization name of the library where to is defined
- `to_artifactId` (chr): artifact name of the library where to is defined
- `to_version` (chr): version of the library where to is defined
- `to_scope` (chr): a `,`-separated tags:
    - `compile` - in a compile scope
    - `test` - in a test scope
    - `managed` - in an SBT managed directory (i.e. a generated source)
    - `dependency` - in a dependency in respect to the module (group_id:artifact_id)
    - `transitive` - in a transitive depenency
- `to_compilation_unit` (chr): the fully qualified name of the enclosing compilation unit of the to parameter
- `to_language` (chr): either `SCALA` or `JAVA`

It was created by [ImplicitConversionExporter.scala](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ 	ImplicitConversionExporter.scala).

### Implicit parameters

The data frame in `r IMPLICIT_PARAMETERS_F` represents implicit parameter declarations.
For each declaration that carries implicit argument list it contains the following information:

- `project_id` (chr): project name as `github-user-name--github-repository-name`
- `module_id` (chr): module id as `project_id::group_id:artifact_id:version:platform`
- `group_id` (chr): organization name
- `artifact_id` (chr): artifact name
- `version` (chr): version
- `declaration_id` (chr): a declaration id of the implicit conversion
- `declaration_kind` (chr): kind of the declaration
- `declaration_is_implicit` (lgl): is the declaration implicit
- `declaration_is_companion` (lgl): is the declaration a companion def to an implicit class
- `def_group_id` (chr): organization name that defines this declaration
- `def_artifact_id` (chr): artifact name that defines this declaration 
- `def_version` (chr): artifact version
- `def_location_scope`  (chr): a `,`-separated tags:
    - `compile` - in a compile scope
    - `test` - in a test scope
    - `managed` - in an SBT managed directory (i.e. a generated source)
    - `dependency` - in a dependency in respect to the module (group_id:artifact_id)
    - `transitive` - in a transitive depenency
- `parameter_id` (chr): id of the parameter
- `name` (chr): name of the parameter
- `code` (chr): code representation
- `type_id` (chr): id of the parameter type
- `type_kind` (chr): kind of the parameter type
- `type_group_id` (chr): organization name that defines this type
- `type_artifact_id` (chr): artifact name that defines this type
- `type_version` (chr): version of the artifact
- `type_location_scope` (chr): a `,`-separated tags:
    - `compile` - in a compile scope
    - `test` - in a test scope
    - `managed` - in an SBT managed directory (i.e. a generated source)
    - `dependency` - in a dependency in respect to the module (group_id:artifact_id)
    - `transitive` - in a transitive depenency
- `type_local` (chr): either `project` or `module` local, or `NA` for for project external symbols
- `resolved_type_id` (chr): resolved type declaration id
- `resolved_type_kind` (chr): resolved type kind
- `num_type_arguments` (int): number of type arguments the type declaration has
- `num_type_argument_refs` (int): number of type arguments the type declaration has that are type parameters

They were extracted using [ImplicitParameterExporter.scala](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ImplicitParameterExporter.scala).

## Loading data

First, we load the corpus and raw data that came from the `export-implicit` task.

```{r loading declarations}
raw_corpus <- load_if_not_present(raw_corpus, read_csv(CORPUS_STAGE3) %>% filter_final_corpus())
raw_all_declarations <- load_if_not_present(raw_all_declarations, read_data(IMPLICIT_DECLARATIONS_F))
raw_all_callsites <- load_if_not_present(raw_all_callsites, read_data(IMPLICIT_CALLSITES_F))
raw_all_conversions <- load_if_not_present(raw_all_conversions, read_data(IMPLICIT_CONVERSIONS_F))
raw_all_parameters <- load_if_not_present(raw_all_parameters, read_data(IMPLICIT_PARAMETERS_F))
```

Double check there are no duplicates!

```{r}
stopifnot(!any(duplicated(raw_corpus$project_id)))
```


```{r, include=F}
reset_environment <- function() {
  vars <- ls(envir = globalenv())
  vars <- vars[!startsWith(vars, "raw_all")]
  message("Removing: ", str_c(vars, ", "))
  rm(list=vars, envir=globalenv())
}
```


Note: 
- The conditional load is for interactive development of this notebook.
  Loading takes time and they these variables should only be used to derive the actual variables with which we work.

```{r}
index <- function(df) {
  df %>% 
    left_join(select(corpus, project_id, pid), by="project_id") %>% 
    left_join(module_ids, by="module_id") %>% 
    select(pid, mid, project_id, everything()) %>% 
    # TODO -project_id?
    select(-module_id)
}

expand_location <- function(df) {
  df %>%
    mutate(
      is_in_test=str_detect(location_scope, "test"),
      is_in_managed=str_detect(location_scope, "managed"),
      is_in_dependency=str_detect(location_scope, "dependency"),
      # all locations that are transitive, but are not a dependency are not a dependency.
      # the sbt.librarymanagement.ModuleID.isTransitive is not super precise and in some cases 
      # inter-project dependencies will mark as transitive.
      is_in_transitive=str_detect(location_scope, "transitive") & is_in_dependency
    ) %>%
      select(-location_scope) %>%
      select(-location_path, -location_path, -location_uri, -location_pos)
}

expand_access_info <- function(df) {
  df %>%
    mutate(
      is_access_specified=access!="NOT_SPECIFIED",
      is_public=access=="PUBLIC",
      is_private=startsWith(access, "PRIVATE"),
      is_protected=startsWith(access, "PROTECTED")
    ) %>%
      select(-access)
}

expand_is_from_scala <- function(df) {
  df %>%
    mutate(
      is_from_scala=is_in_dependency & startsWith(def_group_id, "org.scala-lang")
    )
}

expand_platform <- function(df) {
  df %>%
    mutate(
      is_jvm=str_detect(module_id, ":jvm$"),
      is_js=str_detect(module_id, ":js$"),
      is_native=str_detect(module_id, ":native$"),
    )
}

expand_module_name <- function(df) {
  df %>%
    mutate(
      module_name=str_replace(module_id, "^[^:]+::(.*):[^:]+:[^:]+$", "\\1")
    )
}

remove_scala_version_from_id <- function(df, column) {
  column <- enquo(column)
  df %>%
    mutate(
      !!column:=str_replace(!!column, "(.*)_2.\\d{2}$", "\\1")
    )
}
```

## Clean data

There are couple of inaccuracies in the data gathering.
This section tries to clean them up:

1. In some cases, we are not able to resolve the library in which a declaration has been defined.
   This usually happend when the classpath for the project is not properly configured.
   We have seen this mostly with projects requiring some native packages with Java API.
   
2. There was some inference with parallel job execution and a few projects have in their module_id some undesired output from make.
   
How many are there:

```{r missing library info}
missing_declarations_library <- 
  filter(raw_all_declarations, is.na(def_group_id)) %>%
  select(project_id, module_id, declaration_id)

missing_callsites_library <- 
  semi_join(raw_all_callsites, missing_declarations_library, by=c("module_id", "declaration_id")) %>%
  select(project_id, module_id, declaration_id)

bad_module_id_declarations <- 
  filter(raw_all_declarations, str_detect(module_id, "make\\[")) %>%
  distinct(module_id)

bad_module_id_callsites <- 
  bind_rows(
    filter(raw_all_callsites, str_detect(module_id, "make\\[")),
    semi_join(raw_all_callsites, bad_module_id_declarations, by="module_id")
  ) %>%
  distinct(module_id)
```

```{r}
overview_table(
  r("clean declarations missing library info", missing_declarations_library),
  r("clean declarations missing library info projects", count(missing_declarations_library, project_id)),
  r("clean callsites missing library info", missing_callsites_library),
  r("clean callsites missing library info projects", count(missing_callsites_library, project_id)),
  r("clean missing library info affected projects", 
    length(unique(c(missing_declarations_library$project_id, missing_callsites_library$project_id)))),
  r("clean bad module ids", distinct(bind_rows(bad_module_id_declarations, bad_module_id_callsites)))
)
```

```{r clean}
clean_declarations <- 
  raw_all_declarations %>%
  anti_join(missing_declarations_library, by=c("module_id", "declaration_id")) %>%
  anti_join(bad_module_id_declarations, by="module_id")

clean_callsites <- 
  raw_all_callsites %>%
  anti_join(missing_callsites_library, by=c("module_id", "declaration_id")) %>%
  anti_join(bad_module_id_callsites, by="module_id")

clean_conversions <-
  raw_all_conversions %>%
  semi_join(clean_declarations, by=c("module_id", "declaration_id"))  

clean_parameters <-
  raw_all_parameters %>%
  semi_join(clean_declarations, by=c("module_id", "declaration_id"))

clean_corpus <-
  raw_corpus %>%
  semi_join(clean_declarations, by="project_id")
```


```{r clean data set overview}
lost_rows_pct <- function(orig, curr) {
  percent(1-nrow(curr)/nrow(orig))
}

overview_table(
  overview_projects("Clean corpus", clean_corpus, code_column=metadata_scala_code),
  r("Lost declarations", lost_rows_pct(raw_all_declarations, clean_declarations)),
  r("Lost callsites",    lost_rows_pct(raw_all_callsites, clean_callsites)),
  r("Lost conversion ",  lost_rows_pct(raw_all_conversions, clean_conversions)),
  r("Lost parameters",   lost_rows_pct(raw_all_parameters, clean_parameters))
)
```

## Preprocessing

The `corpus` variable contains project metadata information.
We only consider projects for which the extractor run successfully (which transitively implies that the project was compiled and semanticdb was generated) and that contains some compile Scala code (there are projects that do contain Scala code, but none is being compile).

### Indexing

We build the index using declarations modules which should always include all.
There should not be a call site from a module which does not
appear in declaration.

```{r}
declarations_module_ids <- count(clean_declarations, module_id)
callsites_modules_ids <- count(clean_callsites, module_id)

stopifnot(nrow(anti_join(callsites_modules_ids, declarations_module_ids, by="module_id")) == 0)
```

```{r}
corpus <- 
  clean_corpus %>%
  mutate(
    pid=1:length(project_id)
  ) %>%
  select(pid, everything())

module_ids <-
  declarations_module_ids %>%
  transmute(
    mid=1:length(module_id),
    module_id
  )

project_libraries <-
  clean_declarations %>%
  expand_module_name() %>%
  select(def_project=project_id, def_library_full=module_name) %>%
  distinct(def_project, def_library_full)
```

```{r all declarations}
all_declarations <- 
  clean_declarations %>%
  expand_module_name() %>%
  expand_platform() %>%
  expand_location() %>%
  expand_access_info() %>%
  expand_is_from_scala() %>%
  index()
```

Check the mutually exclusive flags:

```{r all declarations check, eval=F}
check_all_declarations <-
  all_declarations %>%
    rowwise() %>%
    mutate(
      check_platform=sum(is_jvm, is_js, is_native),
      check_access=if (is_access_specified) sum(is_public, is_private, is_protected) else 1
    ) %>%
    filter(
      check_platform != 1,
      check_access != 1
    )

stopifnot(nrow(check_all_declarations) == 0)
```

```{r callsites}
all_callsites <- 
  clean_callsites %>%
  expand_module_name() %>%
  expand_location() %>%
  index()
```

```{r conversions}
all_conversions <- 
  clean_conversions %>%
  expand_module_name() %>%
  index()
```

```{r parameters}
all_parameters <- 
  clean_parameters %>%
  expand_module_name() %>%
  index()
```

## Joining data

```{r}
declarations <-
  all_declarations %>%
  remove_scala_version_from_id(def_artifact_id) %>%
  mutate(
    def_library=def_group_id,
    def_library_full=str_c(def_group_id, ":", def_artifact_id),
    num_implicit_parameters=replace_na(num_implicit_parameters, 0)
  )
```

```{r}
callsites <-
  left_join(
    all_callsites,
    select(
      declarations, 
      mid, 
      declaration_id, 
      is_access_specified,
      is_public,
      is_from_scala,
      def_library,
      def_library_full
    ),
    by=c("mid", "declaration_id")
  )
```

```{r}
conversions <-
  all_conversions %>%
  remove_scala_version_from_id(from_artifactId) %>%
  remove_scala_version_from_id(to_artifactId) %>%
  transmute(
    mid,
    declaration_id,
    from,
    from_group_id=from_groupId,
    from_artifact_id=from_artifactId,
    from_library=str_c(from_group_id, ":", from_artifact_id),
    from_compilation_unit,
    to,
    to_group_id=to_groupId,
    to_artifact_id=to_artifactId,
    to_library=str_c(to_group_id, ":", to_artifact_id),
    to_compilation_unit,
  ) %>%
  left_join(
    select_at(
      declarations,
      vars(
        mid,
        declaration_id, 
        kind,
        def_library,
        def_library_full,
        num_type_parameters,
        num_parameters,
        num_implicit_parameters,
        github_url,
        starts_with("is_")
      )
    ),
    by=c("mid", "declaration_id")
  ) %>%
  distinct(def_library_full, declaration_id, .keep_all=TRUE) %>%
  select(-mid)
```

```{r}
stopifnot(nrow(clean_declarations) == nrow(all_declarations))
stopifnot(nrow(clean_declarations) == nrow(declarations))
stopifnot(nrow(clean_callsites) == nrow(all_callsites))
stopifnot(nrow(clean_callsites) == nrow(callsites))
```

### Implicit conversions

```{r}
conversions_callsites <- semi_join(callsites, conversions, by=c("def_library", "declaration_id"))
conversions_test_callsites <- filter(conversions_callsites, is_in_test)
```

```{r}
projects_using_implicit_conversion <- count(conversions_callsites, pid)
projects_using_implicit_conversion_non_scala <- filter(conversions_callsites, !is_from_scala) %>% count(pid)
projects_using_implicit_conversion_non_test <- filter(conversions_callsites, !is_in_test) %>% count(pid)

implicit_test_callsites <- nrow(filter(callsites, is_in_test))
all_test_callsites <- implicit_test_callsites + sum(corpus$explicit_test_callsites)

conversion_from_scala <- filter(conversions_callsites, is_from_scala)

test_libraries <- tibble(
  def_library=c(
    "org.scalatest",
    "org.spec2",
    "org.scalastic"
  )
)

conversion_from_testlib <- filter(conversions_callsites)
```

```{r}
overview_table(
  r("projects using implicit conversion", projects_using_implicit_conversion),
  r("projects using implicit conversion pct", percent(nrow(projects_using_implicit_conversion)/nrow(corpus))),
  
  r("conversion callsites", conversions_callsites),
  r("conversion callsites in all implicit callsites pct", percent(nrow(conversions_callsites)/nrow(callsites))),
  r("conversion callsites in all callsites pct", percent(nrow(conversions_callsites)/sum(corpus$callsites))),
  
  r("conversion test callsites", conversions_test_callsites),
  r("conversion test callsites in all conversion pct", percent(nrow(conversions_test_callsites)/nrow(conversions_callsites))),
  r("conversion test callsites in all implicit test callsites pct", percent(nrow(conversions_test_callsites)/implicit_test_callsites)),
  r("conversion test callsites in all test callsites pct", percent(nrow(conversions_test_callsites)/all_test_callsites)),
  
  r("conversion callsites from scala pct", percent(nrow(conversion_from_scala)/nrow(conversions_callsites)))
  r("conversion callsites from scala test libraries", percent(nrow(conversion_from_testlib)/nrow(conversions_callsites)))
)
```



```{r}
my_top_count <- function(df, wt, N=50) {
  count(df, !!enquo(wt)) %>% arrange(desc(n)) %>% print(n=N)
}
```

```{r}
my_top_count(conversions_callsites, def_library)
my_top_count(filter(conversions_callsites, !is_in_test), def_library)
my_top_count(filter(conversions_callsites, !is_in_test, !is_from_scala), def_library)
```


```{r}
conversions_callsites_per_project <- 
  conversions_callsites %>%
  count(project_id, def_library, declaration_id)

conversions_callsites_cumul_per_projects <-
  conversions_callsites %>%
  count(project_id)

converions_popularity <-
  left_join(
    conversions_callsites_per_project,
    rename(conversions_callsites_cumul_per_projects, all=n),
    by="project_id"
  ) %>%
  mutate(
    r=n/all
  )
```

```{r}
count(conversions_callsites, def_library, def_library_full) %>%
  left_join(project_libraries, by="def_library_full") %>%
  mutate(def_project=ifelse(is.na(def_project), def_library, def_project)) %>%
  select(def_project, n) %>%
  group_by(def_project) %>%
  summarise(n=sum(n)) %>%
  arrange(desc(n))

```


```{r}
  conversions_callsites %>%
  count(def_library, declaration_id, project_id) %>%
  count(def_library, declaration_id) %>%
  arrange(desc(n)) %>%
  View()
```


```{r}
local({
  threshold <- .03
  all_main <- nrow(conversions_callsites)-nrow(conversions_test_callsites)
  all_test <- nrow(conversions_test_callsites)
  
  main_vs_test <- all_main/(all_main + all_test)

  conversion_callsites_summaries <- 
    conversions_callsites %>%
    group_by(def_library) %>%
    summarise(main=sum(!is_in_test)/all_main, test=sum(is_in_test)/all_test) %>%
    gather("key", "value", main, test)

  top_libraries <- 
    filter(conversion_callsites_summaries, value >= threshold)
 
  df <- 
    top_libraries %>%
    add_row(
      def_library="rest",
      key="main",
      value=1-sum(filter(top_libraries, key=="main")$value)
    ) %>%
    add_row(
      def_library="rest",
      key="test",
      value=1-sum(filter(top_libraries, key=="test")$value)
    ) %>%
    group_by(key) %>%
    arrange(value) %>%
    mutate(
      ymax=cumsum(value),
      ymin=ymax-value,
      xmin=if_else(key=="main", 0, main_vs_test),
      xmax=if_else(key=="main", main_vs_test, 1),
      x=xmin+(xmax-xmin)/2,
      y=ymin+(ymax-ymin)/2
    ) %>%
    arrange(key, value)

  stopifnot(sum(filter(df, key=="main")$value)==1)
  stopifnot(sum(filter(df, key=="test")$value)==1)
    
  df %>%
    ggplot(aes(x=x, y=y, xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, fill=def_library, label=def_library)) + 
    geom_rect() +
    geom_text(aes(color=ifelse(value > .2, "light", "dark"))) +
    scale_fill_brewer("Greens") +
    scale_x_continuous(
      breaks=c(main_vs_test/2, main_vs_test+(1-main_vs_test)/2),
      labels=c("Main code", "Test code")
    ) +
    scale_color_manual(
      values=c("light"="white", "dark"="black"),
    ) +
    guides(
      color=F,
      fill=F
    ) +
    theme(
      axis.title = element_blank(),
      axis.ticks = element_blank(),
      panel.grid = element_blank(),
      axis.text.y = element_blank(),
      axis.text.x = element_text(size=12)
    )
})
```


```{r}
count(conversion_callsites, project_id) %>% arrange(desc(n))
count(all_conversions, project_id) %>% arrange(desc(n))
```

```{r}
projects_not_using_implicit_conversion <- anti_join(corpus, projects_using_implicit_conversion, by="pid")
```

```{r}

```


- from java / scala
- both ways
- scala collections
- primitives
- unrelated

