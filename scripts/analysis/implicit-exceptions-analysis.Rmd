---
title: "Untitled"
output: html_document
---

#### Failed metadata, but has semanticdb

These are errors should be investigated closely, since extracting metadata should in general have less problems that generating semanticdb.
However, with SBT no one really knows.

```{r}
sdb_no_metadata <- filter(stage3_corpus, metadata_exit_code != 0, semanticdb_exit_code == 0) %>%
  select(project_id, metadata_exit_code, metadata_failure, metadata_failure_detail, metadata_duration, metadata_scala_code, gh_stars)
```

```{r}
sdb_no_metadata %>%
  count(metadata_failure) %>% 
  my_datatable()
```

```{r}
sdb_no_metadata %>% 
  my_datatable()
```

### Metadata and semanticdb errors

This is to guess what has happened.
Execution of each phase is stored in a log file.
The log files are stored in `<project_directory>/_analysis_/<phase>.log` where phase is one if (`compile`, `metadata`, `semanticdb`, `implcits`).
We query these log files for a number of regular expressions that identify common failures.
They are decribed in the `[guess_failure_cause](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/scripts/inc/functions.R#L181)` function.

```{r}
failed_projects <- filter(
  stage3_corpus, 
  metadata_exit_code == 1 | 
    (metadata_exit_code == 0 & semanticdb_exit_code == 1)
) %>%
  mutate(
    phase=case_when(
      metadata_exit_code == 1 ~ "metadata",
      semanticdb_exit_code == 1 ~ "semanticdb",
      TRUE ~ as.character(NA)
    ),
    cause=if_else(metadata_exit_code == 1, metadata_failure, semanticdb_failure),
    cause_detail=if_else(metadata_exit_code == 1, metadata_failure_detail, semanticdb_failure_detail),
    duration=if_else(phase=="metadata", metadata_duration, semanticdb_duration)
  ) %>%
  select(project_id, phase, cause, cause_detail, metadata_scala_code, gh_stars)
```

Summarized by exceptions:

```{r}
count(failed_projects, cause) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

```{r}
overview_table(
  r("failed projects",                        filter(stage2_corpus, implicits_exit_code!=0 | is.na(metadata_scala_code))),
  r("failed projects - missing dependencies", filter(failed_projects, cause=="missing-dependencies")),
  r("failed projects - compile error",        filter(failed_projects, cause=="compilation-failed")),
  r("failed projects - broken build",         filter(failed_projects, cause=="project-loading-failed")),
  r("failed projects - empty build",          filter(stage2_corpus, implicits_exit_code==0, is.na(metadata_scala_code))),
  r("failed projects - missing scalajs",      filter(failed_projects, cause=="missing-dependencies", str_detect(cause_detail, "scalajs"))),
  r("failed projects - missing snapshots",    filter(failed_projects, cause=="missing-dependencies", str_detect(cause_detail, "SNAPSHOT")))
)
```


#### Missing dependencies

Missing dependencies is a common failure.
This section gives an overview which dependencies are missing to help to indentify if there are some patterns.
The `guess_failure_cause` function only considers the first missing dependency.

```{r}
count(filter(failed_projects, cause=="missing-dependencies"), cause_detail) %>% arrange(desc(n)) %>% my_datatable(colnames=c("Dependency", "Count"))
```

Notes:
- The `scalajs` is possibly missing because it has been removed due to some security vulnerabilities is some particular version.

#### List of Java errors

The list of JVM errors reported during any of the phases.
This helps us to identify if there are some patterns.

```{r}
filter(failed_projects, cause=="java-error") %>%
  mutate(
    log=make_corpus_link(path(project_id, "_analysis_", str_c(phase, ".log")))
  ) %>%
  select(-phase, -cause) %>%
  select(project_id, log, everything()) %>%
  my_datatable(escape=FALSE)
```


#### List of unknown problems

This is just to see of peraps there is something that could be done about it.
For our experience, these are simply broken builds.

```{r}
filter(failed_projects, cause=="unknown") %>%
  mutate(
    log=make_corpus_link(path(project_id, "_analysis_", str_c(phase, ".log")))
  ) %>%
  select(-phase, -cause) %>%
  select(project_id, log, everything()) %>%
  my_datatable(escape=FALSE)
```

## Missing Semanticdb

In some cases, the semanticdb would run, but not generate any output.
This is just a safety measure to list projects for which the pipeline reports a successful semanticdb generation, yet they need a manual inspection since no output has been generated.

```{r}
filter(corpus, semanticdb_exit_code==0, is.na(semanticdb_files) | semanticdb_files==0) %>%
  mutate(path=make_corpus_link(project_id)) %>%
  select(project_id, path, metadata_exit_code, scala_version, commit_count, gh_stars, metadata_scala_code) %>%
  my_datatable(escape=FALSE)
```

## Errors in implicit extraction

The final phase runs the [implicit extractor](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ExtractImplicits.scala).
The extractor takes the generated semanticdb files together with the extracted metadata and build a [model](https://github.com/PRL-PRG/scala-implicits-analysis/blob/master/libs/model/src/main/protobuf/model.proto) of implicits.
Not all implcits that we find the semanticdb can be resolved and stored in our model.
There is a number of issues that can appear, but the main ones are:
- missing symbol - the implicit is referencing a symbol that cannot be found in neither the semanticdb nor the class path extracted from SBT
- unsupported type - semanticdb defines 14 different [Scala types](https://github.com/scalameta/scalameta/blob/master/semanticdb/semanticdb3/semanticdb3.md#scala-type). We do not support structural, dependent and existential types.
- missing term - the implicit call sites are injected by compiler. These are represented in semanticdb as AST [nodes](https://github.com/scalameta/scalameta/blob/master/semanticdb/semanticdb3/semanticdb3.md#tree) which are different from Scala AST. Our tool tries to map terms from one to the other, but it might not be possible every time. 

### Failures

This lists failures encountered when trying to extract implicits from semanticdb.
A failure is when the running the extractor did not terminate normally.

```{r}
filter(corpus, !is.na(implicit_failure)) %>%
  select(project_id, implicit_failure, metadata_scala_code, gh_stars) %>%
  my_datatable()
```

Notes:
- The `ZipException: error in opening zip file` means that it could not open a a dependency jar file.

### Errors

When extracting implicit declarations and call sites, there can be a number of problems.
Each of the gets logged into an ``r IMPLICITS_EXCEPTIONS`` files.
The following is their classification based on a number of regular expressions.

```{r load implicit errors}
exceptions <- read_data(IMPLICIT_EXCEPTIOSN_F)
```

```{r}
classified_exceptions <- 
  mutate(
    exceptions,
    class=case_when(
      exception == "SymbolNotFoundException" & str_detect(message, "local\\d+") ~ "missing-local-symbol",
      exception == "SymbolNotFoundException" & str_detect(message, "symbol: local\\d+") ~ "missing-local-symbol",
      exception == "SymbolNotFoundException" & str_detect(message, "at Range\\(\\d+,\\d+,\\d+,\\d+\\)") ~ "missing-symbol-at-range",
      exception == "SymbolNotFoundException" ~ "missing-symbol-other",
      exception == "LoadingMetadataException" & str_detect(message, "No module found") & str_detect(message, "multi-jvm") ~ "missing-module-multijvm",
      exception == "LoadingMetadataException" & str_detect(message, "No module found") ~ "missing-module",
      exception == "LoadingMetadataException" ~ "metadata-loading",
      exception == "NotImplementedError" ~ "not-implemented",
      exception == "UnexpectedElementException" ~ "unexpected-element",
      exception == "UnsupportedElementException" ~ "unsupported-element",
      exception == "UnExtractableCallSiteException" & cause == "SymbolNotFoundException" ~ "unextractable-callsite-missing-term",
      exception == "UnExtractableCallSiteException" & cause == "FunctionNotFoundException" ~ "unextractable-callsite-missing-function",
      exception == "UnExtractableCallSiteException" ~ "unextractable-callsite-other",
      exception == "ImplicitArgumentNotFoundException" ~ "missing-implicit-arguments",
      exception == "Exception" & str_detect(message, "^Invalid call site argument") ~ "invalid-declaration",
      TRUE ~ "unclassified"
    )
  )
```

#### Per project summary

```{r}
count(classified_exceptions, project_id) %>% 
  left_join(select(corpus, project_id, metadata_scala_code, gh_stars), by="project_id") %>%
  arrange(desc(n)) %>% 
  my_datatable() 
```

#### Per error class summary

```{r}
count(classified_exceptions, class) %>% arrange(desc(n)) %>% my_datatable()
```

#### Per project and error class summary

```{r}
count(classified_exceptions, project_id, class) %>% arrange(desc(n)) %>% my_datatable()
```

#### Missing symbols

Missing local symbols (symbols defined just a block - we do not need to worry about them).

```{r}
filter(classified_exceptions, class=="missing-local-symbol") %>% 
  count(project_id) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

Missing symbols from a range when aligning the two ASTs.

```{r}
filter(classified_exceptions, class=="missing-symbol-at-range") %>% 
  count(project_id) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

All other missing symbols.

```{r}
filter(classified_exceptions, class=="missing-symbol-other") %>% 
  count(project_id) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

The following is a list of the missing symbols.
This might help us to identify is there are some patterns.

```{r}
filter(classified_exceptions, class=="missing-symbol-other") %>% 
  transmute(project_id, symbol=str_replace_all(message, ".*symbol: (.*)$", "\\1")) %>%
  count(project_id, symbol) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

#### Unclassified

These are all the other errors that occured

```{r}
filter(classified_exceptions, class=="unclassified") %>%
  select(project_id, module_id, class, everything()) %>%
  my_datatable()
```

### Callsites and implicit callsites

A quick overview of the implicit call sites and implicit declarations.

```{r}
filter(corpus, implicits_exit_code==0, metadata_scala_code > 100) %>%
  mutate(
    outlier=is_outlier(callsites)|is_outlier(implicit_callsites),
    label=if_else(outlier, str_glue("{project_id}"), as.character(NA))
  ) %>%
  ggplot(
    aes(
      x=callsites, 
      y=implicit_callsites, 
      label=label, 
      color=if_else(scaladex, "Library", "Application")
    )
  ) +
    geom_point(size=.5) +
    geom_text(size=3, check_overlap = T, vjust=1.5, na.rm = TRUE) + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) +
    geom_vline(aes(xintercept=mean(callsites)), linetype=2, color="black", size=.2) + 
    geom_hline(aes(yintercept=mean(implicit_callsites)), linetype=2, color="black", size=.2) +
    labs(
      title="Ratio of regular call sites and implicit call sites",
      x="Number of callsites (log)", 
      y="Number of implicit callsites (log)", 
      color="Project type"
    )
```

```{r}
filter(corpus, implicits_exit_code==0, metadata_scala_code>0) %>%
  mutate(
    outlier=is_outlier(metadata_scala_code)|is_outlier(implicit_local_declarations),
    label=if_else(outlier, str_glue("{project_id}"), as.character(NA))
  ) %>%
  ggplot(
    aes(
      x=metadata_scala_code, 
      y=implicit_local_declarations, 
      label=label, 
      color=if_else(scaladex, "Library", "Application")
    )
  ) +
    geom_point(size=.5) +
    geom_text(size=3, check_overlap = T, vjust=1.5, na.rm = TRUE) + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) +
    geom_vline(aes(xintercept=mean(metadata_scala_code)), linetype=2, color="black", size=.2) + 
    geom_hline(aes(yintercept=mean(implicit_local_declarations)), linetype=2, color="black", size=.2) +
    labs(
      title="Ratio of regular source code size and number of implicit decalarations",
      x="Source lines of code (log)", 
      y="Number of local declarations (log)", 
      color="Project type"
    )
```

### Time of the successfull projects

Finally, we report the time each phase took for the successful projects.
This gives a hint about how long rebuilding the repository of passing projects will take.

```{r}
make_stats(
  add_num("Metadata extraction time", corpus$metadata_duration),
  add_num("Compile time", corpus$compile_duration),
  add_num("Semanticdb extraction time", corpus$semanticdb_duration),
  add_num("Implicits extraction time", corpus$implicits_duration)
) %>%
  my_datatable()
```
