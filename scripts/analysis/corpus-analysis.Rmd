---
title: "Corpus analysis"
output: html_document
params:
  base_dir: /var/lib/scala/corpora/scaladex
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(fs)
library(tidyverse)
library(ggplot2)
library(DT)
library(lubridate)
library(knitr)

theme_set(theme_minimal())
source("inc/paths.R")
source("inc/stats.R")
```

## Corpus

```{r}
all_projects_names <- readLines(ALL_PROJECTS_FILE)
downloaded <- basename(dir_ls(ALL_PROJECTS_DIR, recursive = FALSE))

repo_metadata <- read_csv(REPO_METADATA) %>%
  mutate(
    commit_date=as_datetime(commit_date),
    first_commit_date=as_datetime(first_commit_date)
  )

repo_metadata_scala <- filter(repo_metadata, scala_code > 0)
repo_metadata_sbt <- filter(repo_metadata_scala, build_system=="sbt")
repo_metadata_sbt_compatible <- filter(repo_metadata_sbt, startsWith(sbt_version, "1.") | startsWith(sbt_version, "0.13"))
```

We have three corpuses:

- top100
- scaladex
- github

The TOP100 were from github in October 2018.
The `scaladex/all-projects.txt` was generated by querying [scaladex index](http://index.scala-lang.org/) in January 2019
The `github/all-projects.txt` was generated from ghtorrent from January 2019.

```{r}
make_stats(
  add_num("All Scala projects", length(all_projects_names)),
  add_num("Downloaded projects", length(downloaded)),
  # a git fetching problem - only created an empty directory
  add_num("Downloaded empty projects", length(downloaded)-nrow(repo_metadata)),
  add_num("Projects with no Scala code", nrow(repo_metadata)-nrow(repo_metadata_scala)),
  add_num("Scala projects", nrow(repo_metadata_scala)),
  add_num("SBT projects", nrow(repo_metadata_sbt)),
  # defines sbt.version >= 0.13 | 1.0
  add_num("Compatible SBT projects", nrow(repo_metadata_sbt_compatible))
)
```

### Overview of the build systems

```{r}
count(repo_metadata_scala, build_system) %>% 
  replace_na(list(build_system="unknown")) %>% 
  arrange(desc(n)) %>% 
  knitr::kable(col.names = c("Build system", "Count"))
```

### Overview of the sbt versions

```{r}
filter(repo_metadata_scala, build_system=="sbt") %>% 
  count(sbt_version) %>% 
  replace_na(list(sbt_version="Not specified")) %>% 
  arrange(desc(n)) %>%
  knitr::kable(col.names = c("SBT version", "Count"))
```

#### Missing sbt.version

```{r}
missing_sbt_version <- 
  filter(repo_metadata_scala, build_system == "sbt", is.na(sbt_version)) %>%
  mutate(
    sbt_properties=path(params$base_dir, "all-projects", project_id, "project", "build.properties"), 
    sbt_properties=ifelse(file_exists(sbt_properties), sbt_properties, NA)
  ) %>%
  select(project_id, commit_count, scala_code, sbt_properties)
```

The following projects do not know that it is `sbt.version` and use
`bt.version` or `sbtversion` :-)

```{r}
filter(missing_sbt_version, !is.na(sbt_properties))
```

The following projects do not care, as they do not define `build.properties`:
```{r}
filter(missing_sbt_version, is.na(sbt_properties))
```

## Projects

```{r loading corpus}
corpus <- read_csv(CORPUS)
```

```{r phase cause detection}
for (phase in c("metadata", "compile", "semanticdb")) {
  phase_problems <- 
    filter(corpus, (!!sym(str_c(phase, "_exit_code")))==1) %>% 
    mutate(log_file=path(project_path, "_analysis_", str_c(phase, ".log"))) %>%
    phase_failure_cause() %>%
    group_by(project_id) %>%
    summarise(cause=cause[1], detail=detail[1]) %>%
    ungroup() %>%
    select(
      project_id,
      !!sym(str_c(phase, "_cause")):=cause,
      !!sym(str_c(phase, "_cause_detail")):=detail
    )
    
  corpus <-
    left_join(
      corpus,
      phase_problems,
      by="project_id"
    )

  rm(phase_problems)
}
```

```{r projects stats}
n_sbt_projects <- length(read_lines(SBT_PROJECTS_FILE))
n_so_projects <- length(read_lines(SO_PROJECTS_FILE))
n_projects <- length(read_lines(PROJECTS_FILE))

make_stats(
  add_num("Compatible SBT projects", nrow(repo_metadata_sbt_compatible)),
  add_num("In sbt_projects_txt", n_sbt_projects),
  add_num("In so_projects_txt", n_so_projects),
  add_num("In projects_txt", n_projects),
  add_num("Duplicate projects", n_sbt_projects - n_so_projects),
  add_num("Missed projects", n_projects - nrow(corpus)),
  add_num("Processed projects", nrow(corpus)),
  add_num("Scala SLOC in project", corpus$repo_scala_code),
  add_num("Scala files in project", corpus$repo_scala_files),
  add_num("Scala SLOC reported by SBT", corpus$metadata_scala_code),
  add_num("Scala files reported by SBT", corpus$metadata_scala_files),
  add_num("Github Stars", corpus$github_stars),
  add_num("Libraries", sum(corpus$scaladex)),
  add_num("Apps", sum(!corpus$scaladex)),
  add_num("Extracted metadata", sum(corpus$metadata_exit_code==0)),
  add_num("Compiled", sum(corpus$compile_exit_code==0)),
  add_num("Extracted semanticdb", sum(corpus$semanticdb_exit_code==0)),
  add_num("Extracted implicits", sum(corpus$implicits_exit_code==0)),
  add_num("Dejavu cosidered files", corpus$dejavu_files),
  add_num("Dejavu duplicated files", corpus$dejavu_duplicated_files),
  add_num("Dejavu missed files", corpus$repo_scala_files - corpus$dejavu_duplicated_files),
  add_num("Dejavu duplication", corpus$dejavu_duplication),
  add_num("Implicit declarations", corpus$implicit_declarations),
  add_num("Implicit call sites", corpus$implicit_callsites),
  add_num("Call sites", corpus$callsites),
  add_num("Errors in implicit extrcation", corpus$implicit_problems),
  add_num("Failures in running implicit extractor", sum(!is.na(corpus$implicit_failure)))
) %>%
  datatable(options=list(paging=FALSE, searching=FALSE, info=FALSE))
```

## Pipeline

```{r}
pipeline_overview <-
  corpus %>%
  transmute(metadata=metadata_exit_code==0, compile=compile_exit_code==0, sdb=semanticdb_exit_code==0, implicits=implicits_exit_code==0, sloc=repo_scala_code, stars=github_stars)

tribble(
  ~phase,       ~projects,                        ~SLOC,                                          ~stars,
  "Start",      nrow(corpus),                     sum(corpus$repo_scala_code),                    sum(corpus$github_stars), 
  "Metadata",   sum(pipeline_overview$metadata),  sum(filter(pipeline_overview, metadata)$sloc),  sum(filter(pipeline_overview, metadata)$stars),
  "Compile",    sum(pipeline_overview$compile),   sum(filter(pipeline_overview, compile)$sloc),   sum(filter(pipeline_overview, compile)$stars),
  "Semanticdb", sum(pipeline_overview$sdb),       sum(filter(pipeline_overview, sdb)$sloc),       sum(filter(pipeline_overview, sdb)$stars),
  "Implicits",  sum(pipeline_overview$implicits), sum(filter(pipeline_overview, implicits)$sloc), sum(filter(pipeline_overview, implicits)$stars)
) %>%
  mutate_at(vars(-phase), fmt) %>%
  datatable(options=list(paging=FALSE, searching=FALSE, info=FALSE))
```

### Errors

```{r}
phases <- c("metadata", "compile", "semanticdb", "implicits")
phases_data <- list(
  select(corpus, project_id, exit_code=metadata_exit_code),
  select(corpus, project_id, exit_code=compile_exit_code),
  select(corpus, project_id, exit_code=semanticdb_exit_code),
  select(corpus, project_id, exit_code=implicits_exit_code)
)
status <- map2_dfr(phases, phases_data, ~phase_status(.x, .y)) %>% mutate_at(vars(-phase), function(x) coalesce(x, 0))
status %>% kable()
```

#### Failed metadata, but has semanticdb

```{r}
sdb_no_metadata <- filter(corpus, metadata_exit_code != 0, semanticdb_exit_code == 0) %>%
  select(project_id, metadata_exit_code, metadata_cause, metadata_cause_detail, metadata_duration, repo_scala_code, repo_scala_files, github_stars)
```

```{r}
sdb_no_metadata %>% datatable()
```

```{r}
sdb_no_metadata %>%
  count(metadata_cause) %>% 
  simple_datatable()
```

#### Metadata and semanticdb errors

```{r}
failed_projects <- filter(
  corpus, 
  metadata_exit_code == 1 | 
    (metadata_exit_code == 0 & semanticdb_exit_code == 1)
) %>%
  mutate(
    phase=case_when(
      metadata_exit_code == 1 & semanticdb_exit_code == 1 ~ "metadata, semanticdb",
      metadata_exit_code == 1 ~ "metadata",
      semanticdb_exit_code == 1 ~ "semanticdb"
    ),
    cause=if_else(metadata_exit_code == 1, metadata_cause, semanticdb_cause),
    cause_detail=if_else(metadata_exit_code == 1, metadata_cause_detail, semanticdb_cause_detail)
  ) %>%
  select(project_id, phase, cause, cause_detail, metadata_duration, repo_scala_code, repo_scala_files, github_stars)
```

```{r}
count(failed_projects, cause) %>% arrange(desc(n))
```

##### Which dependencies

```{r}
count(filter(failed_projects, cause=="missing-dependencies"), cause_detail) %>% arrange(desc(n))
```

##### Which unknown

```{r}
count(filter(failed_projects, cause=="unknown"), cause_detail) %>% arrange(desc(n))
```

##### All problems

```{r}
failed_projects %>% datatable()
```

### Time

```{r}
make_stats(
  add_num("Metadata", corpus$metadata_duration),
  add_num("Compile", corpus$compile_duration),
  add_num("Semanticdb", corpus$semanticdb_duration),
  add_num("Implicits", corpus$implicits_duration)
) %>%
  datatable(options=list(paging=FALSE, searching=FALSE, info=FALSE))
```

## Dejavu

```{r}
corpus %>%
  filter(implicits_exit_code==0, dejavu_duplication > 0) %>%
  ggplot(aes(dejavu_duplication)) +
  geom_histogram(bins=50) +
  scale_x_continuous(labels=scales::percent) +
  labs(title="Dejavu duplication", subtitle="Number of duplicated files / number of files", x="Duplication", y="Number of projects")
```

## Source code vs github stars

```{r}
corpus %>%
  filter(implicits_exit_code==0) %>%
  mutate(
    r=round(github_stars/repo_scala_code, 2),
    outlier=is_outlier(r),# | is_outlier(github_stars) | is_outlier(repo_scala_code),
    label=if_else(outlier, str_glue("{project_id} ({r})"), as.character(NA))
  ) %>%
  ggplot(aes(repo_scala_code, github_stars, label=label)) +
    geom_point(aes(color=factor(outlier))) +
    geom_text(size=3, check_overlap = T, vjust=1.5, na.rm = TRUE) + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) + 
    scale_colour_manual(values = c("TRUE"="red", "FALSE"="black"), labels=c("TRUE"="Yes", "FALSE"="No"), guide=FALSE) +
    labs(title="Source code vs Github stars", x="SLOC (log)", y="GitHub stars", subtitle="outliers - ratio (stars/sloc), sloc, stars")
```

## Source code vs commit vs github stars

```{r}
corpus %>%
  filter(implicits_exit_code==0) %>%
  mutate(
    outlier=is_outlier(commit_count) | is_outlier(github_stars) | is_outlier(repo_scala_code),
    label=if_else(outlier, str_glue("{project_id}"), as.character(NA))
  ) %>%
  ggplot(aes(repo_scala_code, commit_count, size=github_stars, label=label)) +
    geom_point(aes(color=factor(outlier))) +
    geom_text(size=3, check_overlap = T, vjust=1.5, na.rm = TRUE) + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) + 
    scale_colour_manual(values = c("TRUE"="red", "FALSE"="black"), labels=c("TRUE"="Yes", "FALSE"="No"), guide=FALSE) +
    labs(title="Source code vs Github stars", x="SLOC (log)", y="GitHub stars", subtitle="outliers - ratio (stars/sloc), sloc, stars")
```

## Errors in implicit extraction

### Failures

Unexpected exception

```{r}
filter(corpus, !is.na(implicit_failure)) %>%
  select(project_id, repo_scala_code, github_stars) %>%
  mutate_all(fmt)
```
### Errors

```{r load implicit errors}
exceptions <- read_csv(IMPLICITS_EXCEPTIONS, col_types="cccccccc")
```

```{r}
classified_exceptions <- 
  mutate(
    exceptions,
    class=case_when(
      exception == "SymbolNotFoundException" & str_detect(message, "local\\d+") ~ "missing-local-symbol",
      exception == "SymbolNotFoundException" & str_detect(message, "symbol: local\\d+") ~ "missing-local-symbol",
      exception == "SymbolNotFoundException" & str_detect(message, "at Range\\(\\d+,\\d+,\\d+,\\d+\\)") ~ "missing-symbol-at-range",
      exception == "SymbolNotFoundException" ~ "missing-symbol-other",
      exception == "LoadingMetadataException" & str_detect(message, "No module found") & str_detect(message, "multi-jvm") ~ "missing-module-multijvm",
      exception == "LoadingMetadataException" & str_detect(message, "No module found") ~ "missing-module",
      exception == "LoadingMetadataException" ~ "metadata-loading",
      exception == "NotImplementedError" ~ "not-implemented",
      exception == "UnexpectedElementException" ~ "unexpected-element",
      exception == "UnsupportedElementException" ~ "unsupported-element",
      exception == "UnExtractableCallSiteException" & cause == "SymbolNotFoundException" ~ "unextractable-callsite-missing-term",
      exception == "UnExtractableCallSiteException" & cause == "FunctionNotFoundException" ~ "unextractable-callsite-missing-function",
      exception == "UnExtractableCallSiteException" ~ "unextractable-callsite-other",
      exception == "ImplicitArgumentNotFoundException" ~ "missing-implicit-arguments",
      exception == "Exception" & str_detect(message, "^Invalid argument") ~ "invalid-declaration",
      TRUE ~ "unclassified"
    )
  )
```

#### Summary per project summary

```{r}
count(classified_exceptions, project_id) %>% arrange(desc(n)) %>% datatable()
```

#### Summary per class summary

```{r}
count(classified_exceptions, class) %>% arrange(desc(n)) %>% datatable()
```

#### Summary per project and class summary

```{r}
count(classified_exceptions, project_id, class) %>% arrange(desc(n)) %>% datatable()
```

#### Missing symbols

##### Local


```{r}
filter(classified_exceptions, class=="missing-local-symbol") %>% count(project_id) %>% arrange(desc(n)) %>% datatable()
```

##### Range

```{r}
filter(classified_exceptions, class=="missing-symbol-at-range") %>% count(project_id) %>% arrange(desc(n)) %>% datatable()
```

##### Other

```{r}
filter(classified_exceptions, class=="missing-symbol-other") %>% count(project_id) %>% arrange(desc(n)) %>% datatable()
```

```{r}
filter(classified_exceptions, class=="missing-symbol-other") %>% 
  transmute(project_id, symbol=str_replace_all(message, ".*symbol: (.*)$", "\\1")) %>%
  count(project_id, symbol) %>% 
  arrange(desc(n)) %>% 
  datatable()
```

#### Unclassified

```{r}
filter(classified_exceptions, exception=="Exception") %>% 
  datatable()
```

