---
title: "Stage 3 Analysis"
authors: Filip Krikava, Jan Vitek and Heather Miller
output:
  html_document:
    code_folding: hide
    theme: united
    toc: true
    toc_float: true
params:
  corpus_dir: /var/lib/scala/corpora/github
  corpus_url: http://prl1.ele.fit.cvut.cz:8149
  lib_dir: ../inc
  report_name: corpus-analysis
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
source(file.path(params$lib_dir, "setup.R"))
```

```{r output, include=FALSE}
OUT_TOP_PROJECTS_TEX <- path(output_dir, "top-projects.tex")
OUT_CORPUS_OVERVIEW_PDF <- path(output_dir, "corpus-overview.pdf")
OUT_IMPLICITS_OVERVIEW_PDF <- path(output_dir, "implicits-overview.pdf")
```

## Overview

The ``r CORPUS_STAGE3_F`` contains only the projects that were selected in stage 1.
Next to the data collected in ``r CORPUS_STAGE1_F``, it contains details about the stage 2, i.e. the project compilation, SBT metadata extraction, semanticdb generation and implicit extraction.
The goal of the stage 3 is to filter the projects that have been successfully processed and which will be part of the final corpus.

The file contains the following columns:

- `project_id` (chr): project name as `github-user-name--github-repository-name`
- `origin` (chr): the URL to github 
- `build_system` (chr): guessed build system
- `sbt_version` (chr):  guessed sbt version
- `size_repo` (int): of the git versioned files in bytes
- `size` (int): of everything in bytes
- `commit_count` (int): number of commits
- `commit` (chr): current checkout hash
- `commit_date` (dttm): the date of the current commit
- `first_commit_date` (dttm): the date of the first commit
- `scala_code` (int): number of lines of Scala code excluding blanks and comments
- `scala_files` (int): number of Scala files
- `dejavu_n_files` (int): number of files processed by Dejavu (this shall be less than `scala_files` since it only consider non-token-empty ones with `.scala suffix`)
- `dejavu_n_duplicated_files` (int):  number of duplicate files (files seen in other projects)
- `dejavu_duplication` (dbl): `dejavu_n_duplicated_files/dejavu_n_files`
- `gh_name` (chr): GitHub name
- `gh_stars` (int): Number of stars 
- `gh_watchers` (int): Number of watchers
- `gh_created_at` (dttm): When was the project created at GitHub
- `gh_updated_at` (dttm): When was the project last updated at GitHub
- `gh_pushed_at` (dttm): When it has been last pushed to the project at GitHub
- `gh_fork` (lgl): Is it a fork?
- `gh_archived` (lgl): Has it been archived?
- `scaladex` (lgl): Has it been indexed by scaladex?
- `metadata_exit_code` (int): exit code of running `sbt metadata`
- `metadata_duration` (int): how long did it take (in seconds)
- `metadata_scala_code_test_managed` (int): managed Scala code in test
- `metadata_scala_code_test` (int): unmanaged and managed Scala code in test
- `metadata_scala_code_compile_managed` (int): managed Scala code in compile
- `metadata_scala_code_compile` (int): unmanaged and managed Scala code in compile
- `metadata_scala_code` (int): all Scala code above
- `modules` (int): number of subprojects
- `scala_version` (chr): scala version `sbt show scalaVersion` 
- `updated_scala_version` (chr): the scala version we used for semanticdb (some projects need to be updated since semanticdb only supports a subset of Scala versions) 
- `compile_exit_code` (int): exit code of running `sbt compileWithStats`
- `compile_duration` (int): how long did it take (in seconds)
- `compile_classes` (int): number of generated `*.class` files 
- `semanticdb_exit_code` (int): exit code of running `sbt semanticdb`
- `semanticdb_duration` (int): how long did it take (in seconds) 
- `semanticdb_classes` (int): number of generated `*.class` files
- `semanticdb_files` (int): number of generated `*.semanticdb` files
- `semanticdb_occurrences` (int): number of semanticdb occurrences (symbol occurrences)
- `semanticdb_synthetics` (int): number of semanticdb synthetics (what Scala compiler injects - implicits / desuggaring)
- `semanticdb_symbols` (int): number of semanticdb symbols
- `implicits_exit_code` (int): exit code of running the implicit extractor
- `implicits_duration` (int): how long did it take (in seconds)
- `implicit_cause_failure` (chr): the error message given in case of implicit extraction failure
- `declarations` (int): number of resolved declarations
- `implicit_declarations` (int): number of resolved implicit declarations used in the project
- `implicit_local_declarations` (int): number of implicit declarations defined in the project
- `callsites` (int): estimated number of all call sites
- `implicit_callsites` (int): number of call sites involving implicits (a conversion, implicit parameters, both) 
- `implicit_extraction_errors` (int): number of problems encountered when running the extrcator (e.g. improssible to resolve a symbol given a source code location) 
- `metadata_cause` (chr): the cause of metadata failure 
- `metadata_cause_detail` (chr): detail of the cause 
- `compile_cause` (chr): the cause of semanticdb failure 
- `compile_cause_detail` (chr): detail of the cause  
- `semanticdb_cause` (chr): the cause of semanticdb failure 
- `semanticdb_cause_detail` (chr): detail of the cause 

Exit code:
- `0`: all good
- `1`: failure
- `-1`: not run because of failed dependencies
- `>= 130`: timeouted

## Loading data

First, we need to load the data. We have three stages:

- stage 1 - downloads all the projects and gathers the repository-level metadata
- stage 2 - extracts sbt project metadata, compiles and generates semanticdb
- stage 3 - extracts implicits

The `r CORPUS_STAGE1_F` contains information about projects that finished stage 1 and indicates which can go to stage 2 before de-duplication.
The `r CORPUS_STAGE3_F` contains information about projects that went to stage 2 and indicates which managed to pass stage 3.
So `stage1_corpus` contains all Scala projects we could get, `stage2_corpus` contains all compatible de-duplicated projects and `corpus` is the final corpus containing only the projects we could extract implicits from.

```{r loading data}
stage1_corpus <- read_csv(CORPUS_STAGE1)
stage2_corpus <- read_csv(CORPUS_STAGE3)
```

The final corpus only contains projects for which the implicit extractor successfully ran and that have some compiled Scala code.

```{r final corpus}
corpus <- filter_final_corpus(stage2_corpus)
```

Add total call sites:

```{r}
corpus <- mutate(
  corpus,
  explicit_callsites=callsites,
  callsites=implicit_callsites+explicit_callsites
) %>%
  rename(
    explitic_test_callsites=test_callsites
  )
```


### Checks

In the final corpus, the metadata, semanticdb stages should have 0 exit code.

```{r check metadata}
corpus_failed_metadata <- corpus %>% filter(metadata_exit_code != 0)
assert_that(nrow(corpus_failed_metadata) == 0)
```

```{r check semanticdb}
corpus_failed_semanticdb <- corpus %>% filter(semanticdb_exit_code != 0)
assert_that(nrow(corpus_failed_semanticdb) == 0)
```

## Stage 3 Corpus Summary

The following is the result of the corpus after running the stage 2.

```{r projects overview}
compatible_projects <- filter(stage1_corpus, compatible)
duplicated_projects <- anti_join(compatible_projects, stage2_corpus, by="project_id")

overview_table(
  overview_projects("stage one",               stage1_corpus),
  overview_projects("sbt projects",            filter(stage1_corpus, build_system=="sbt")),
  overview_projects("maven projects",          filter(stage1_corpus, build_system=="maven")),
  overview_projects("graddle projects",        filter(stage1_corpus, build_system=="graddle")),
  overview_projects("compatible sbt projects", compatible_projects),
  overview_projects("duplicated",              duplicated_projects),
  overview_projects("stage two",               stage2_corpus)
)
```

```{r projects duplication}
compatible_big_projects <- filter(compatible_projects, scala_code > 5e4)
stage2_big_projects <- filter(stage2_corpus, scala_code > 5e4)

overview_table(
  r("compatilbe big projects", compatible_big_projects),
  r("stage two big projects", stage2_big_projects),
  r("compatible big projects duplication pct", percent(mean(compatible_big_projects$dejavu_duplication))),
  r("stage two big projects duplication pct", percent(mean(stage2_big_projects$dejavu_duplication))),
  r("lost stars in duplicated projects pct", percent(sum(duplicated_projects$gh_stars)/sum(compatible_projects$gh_stars))),
)
```

```{r projects stage 2 details}
extracted_metadata <- filter(stage2_corpus, metadata_scala_code > 0, metadata_exit_code == 0)
generated_semanticdb <- filter(extracted_metadata, semanticdb_exit_code == 0)

scala_code <- sum(corpus$metadata_scala_code)
scala_code_compile <- sum(corpus$metadata_scala_code_compile)
scala_gencode_compile <- sum(corpus$metadata_scala_code_compile_managed)
scala_code_test <- sum(corpus$metadata_scala_code_test)
scala_gencode_test <- sum(corpus$metadata_scala_code_test_managed)
scala_gencode <- scala_gencode_compile + scala_gencode_test

projects_with_tests <- nrow(filter(corpus, metadata_scala_code_test > 0))
projects_without_tests <- nrow(filter(corpus, metadata_scala_code_test == 0))

overview_table(
  overview_projects("extracted metadata",   extracted_metadata, code_column=metadata_scala_code),
  overview_projects("generated semanticdb", generated_semanticdb, code_column=metadata_scala_code),
  overview_projects("corpus", corpus, code_column=metadata_scala_code),

  r("corpus projects gencode", scala_gencode),
  r("corpus projects main code", scala_code_compile),
  r("corpus projects main gencode", scala_gencode_compile),
  r("corpus projects test code", scala_code_test),
  r("corpus projects test gencode", scala_gencode_test),
  r("corpus projects files", sum(corpus$scala_files)),
  r("corpus projects gencode pct", percent(scala_gencode/scala_code)),
  r("corpus projects test pct", percent(scala_code_test/scala_code)),
  r("corpus projects main gencode pct", percent(scala_gencode_compile/scala_code_compile)),
  r("corpus projects test gencode pct", percent(scala_gencode_test/scala_code_test)),
  r("corpus projects with test", projects_with_tests),
  r("corpus projects without test", projects_without_tests),
  r("corpus projects with test pct", percent(projects_with_tests/nrow(corpus))),
)
```

Notes:

```{r compiler benchmakr, include=FALSE}
compiler_benchmark <- filter(corpus, project_id=="scala--compiler-benchmark")
```

- For the final corpus we use `metadata_scala_code` instead of `scala_code`.
  The difference is that `scala_code` is computed using [cloc](https://sourceforge.net/projects/cloc/) with `--vcs=git` so it includes all the Scala files that are in the repository. 
  The `metadata_scala_code` on the other hand includes the code that was actually compiled. 
  It includes the source directories known to SBT (`sbt show sourceDirectories`) which could be a subset of what is stored in the project repository.
  Also it will include generated code.
  The good example is [compiler-benchmark](https://github.com/scala/compiler-benchmark) which has `r fmt(compiler_benchmark$scala_code)` lines of Scala code stored in git (`scala_code`), but only `r fmt(compiler_benchmark$metadata_scala_code)` is actually compiled (`metadata_scala_code`).
  The rest is code from various projects used for menchmarking scalac.

#### Graph

```{r corpus overview plot}
corpus_code_mean <- mean(corpus$metadata_scala_code)
corpus_code_median <- median(corpus$metadata_scala_code)
corpus_commit_mean <- mean(corpus$commit_count)
corpus_commit_median <- median(corpus$commit_count)

corpus %>%
  mutate(
#    outlier=is_outlier(metadata_scala_code)|is_outlier(commit_count)|is_outlier(gh_stars),
    outlier=gh_stars>=5000,
#    outlier=FALSE,
    label=if_else(outlier, str_glue("{project_id}"), as.character(NA))
  ) %>%
  ggplot(
    aes(
      x=metadata_scala_code, 
      y=commit_count, 
      label=label, 
      color=if_else(scaladex, "Yes", "No"),
      size=gh_stars
    )
  ) +
    geom_point(alpha=.6) +
    #geom_text(size=2.5, check_overlap = F, vjust=-1, na.rm = TRUE, color="black") + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) +
    scale_size_continuous(range = c(.1, 8)) +
    scale_color_gdocs() +
  
    geom_hline(aes(yintercept=corpus_commit_mean, linetype="dashed"), color="black", size=0.2) +
    geom_vline(aes(xintercept=corpus_code_mean, linetype="dashed"), color="black", size=0.2) +
    #annotate("text", x=1, y=corpus_commit_mean, label=floor(corpus_commit_mean), hjust=2.4, vjust=-1.0, size=3) + 
    #annotate("text", x=corpus_code_mean, y=1, label=floor(corpus_code_mean), hjust=-.3, vjust=2.4, size=3) + 
  
    geom_hline(aes(yintercept=corpus_commit_median, linetype="solid"), color="black", size=0.2) +
    geom_vline(aes(xintercept=corpus_code_median, linetype="solid"), color="black", size=0.2) +
    #annotate("text", x=1, y=corpus_commit_median, label=floor(corpus_commit_median), hjust=3.2, vjust=-1.0, size=3) + 
    #annotate("text", x=corpus_code_median, y=1, label=floor(corpus_code_median), hjust=-.3, vjust=2.4, size=3) + 
    scale_linetype_manual(labels=c("mean", "median"), values=c("dashed", "solid")) +
    theme(
      legend.position=c(0.25, 0.89),
      legend.box="horizontal"
    ) +
    labs(
      x="Souce lines of code (log)", 
      y="Number of commits (log)", 
      color="In Scaladex",
      size="Github stars",
      linetype=""
    )
```

```{r save plot}
ggsave(OUT_CORPUS_OVERVIEW_PDF)
```


### Implicits

```{r implicits overview}
explicit_callsites <- sum(corpus$explicit_callsites)
implicit_callsites <- sum(corpus$implicit_callsites)
explicit_test_callsites <- sum(corpus$explitic_test_callsites, na.rm = T)
callsites <- sum(corpus$callsites)

overview_table(
  r("implicit extraction errors", sum(corpus$implicit_extraction_errors)),
  r("Implicit extraction failures", filter(corpus, !is.na(implicit_failure))),
  r("implicit declarations", sum(corpus$implicit_declarations)),
  r("local implicit declarations", sum(corpus$implicit_local_declarations)),
  r("call sites", callsites),
  r("explicit call sites", explicit_callsites),
  r("implicit call sites", implicit_callsites),
  r("implicit call sites pct", percent(implicit_callsites/callsites)),
  r("test call sites", explicit_test_callsites),
  r("test call sites pct", percent(explicit_test_callsites/explicit_callsites)),
)
```

#### Graph

```{r implicit overview}
local({

callsite_color <- "#ED6559"
declaration_color <- "#4C5D7C"
  
# the trick with superposition is to do the log10 scaling manually
corpus_implicitness_overview <- 
  corpus %>%
  mutate(
    implicit_local_declarations=if_else(implicit_local_declarations > 0, log10(implicit_local_declarations), 0)
  )

# up to which part of the implicit local declarations can this graph overlap
cs_ds_opverlap <- .4
cs_end <- max(corpus_implicitness_overview$implicit_local_declarations)
# this is the height of the overlap which is equal to 100% of implicit callsites ration
cs_height <- cs_end - 10^(log10(cs_end) - log10(cs_end) * cs_ds_opverlap)

# the implicit callsites ratio will be plotted using segments
# for this we need to compute y and yend (x and xend are the same - project_id)
corpus_implicitness_overview <- 
  corpus_implicitness_overview %>%
  transmute(
    project_id,
    ds=implicit_local_declarations,
    cs=implicit_callsites/callsites,
    cs_start=cs_end - cs_height * cs
  ) %>%
  mutate(
    project_id=forcats::fct_reorder(project_id, ds)
  )

pri_breaks <- seq(cs_end, cs_end*(1-cs_ds_opverlap), length.out = 5)
pri_labels <- seq(0, 100, length.out = length(pri_breaks)) %>% str_c("%")
sec_breaks <- c(0:as.integer(cs_end), cs_end)
sec_labels <- c("0", fmt(10^sec_breaks[-1]))

corpus_implicitness_overview %>%
  ggplot(
    aes(
      x=project_id,
      y=ds
    )
  ) + 
  geom_segment(aes(xend=project_id, y=cs_start, yend=cs_end), color=callsite_color, alpha=.5) +
  geom_bar(width=1, stat="identity", fill=declaration_color, color=declaration_color, alpha=1) +
  theme(
    axis.text.x=element_blank(), 
    axis.ticks.x=element_blank(),
    axis.ticks.y=element_line(),
    panel.grid.major.x=element_blank(), 
    panel.grid.minor.x=element_blank(),
    panel.grid.major.y=element_line(),
    panel.grid.minor.y=element_blank()
  ) + 
  scale_y_continuous(
    breaks=pri_breaks,
    labels=pri_labels,
    name="Ratio of implicit calls",
    sec.axis=sec_axis(
      trans=~.,
      name="Number of implicit declarations (log)",
      breaks=sec_breaks, 
      labels=sec_labels
    ) 
  ) +
  labs(x="Projects")
})
```

```{r save plot}
ggsave(OUT_IMPLICITS_OVERVIEW_PDF)
```

### TOP projects

```{r top projects table}
top_projects <- 
  corpus %>%
  transmute(
    name=str_replace(project_id, "--", "/"),
    name=xtable::sanitize(name),
    name=str_c("\\href{https://github.com/", name, "/}{", name, "}"),
    gh_stars,
    metadata_scala_code,
    commit_count,
    dejavu_duplication,
    scaladex=if_else(scaladex, "Y", "N")
  ) %>%
  top_n(40, gh_stars) %>%
  arrange(desc(gh_stars)) %>%
  mutate_all(fmt) %>%
  rename(
    `Project`=name,
    `GitHub stars`=gh_stars,
    `Code size`=metadata_scala_code,
    `Commits`=commit_count,
    `Duplication`=dejavu_duplication,
    `Scaladex`=scaladex
  )
```

```{r show top projects}
top_projects %>% my_datatable()
```

```{r save top projects}
top_projects %>%
  xtable::xtable(align="llrrrrc") %>%
  print(
    floating=F,
    file=OUT_TOP_PROJECTS_TEX,
    include.rowname=F,
    sanitize.text.function=identity
  )
```

## Heatmaps



### Duplicate projects

The following table show the number of projects (Scala code and GitHub stars) that were removed based on our duplication thresolds.

```{r duplicate projects}
removed_duplicates <- anti_join(filter(stage1_corpus, compatible), stage3_corpus, by="project_id")
make_stats(
  add_nrow("Removed duplicate projects", removed_duplicates),
  add_num("Removed duplicate projects code", sum(removed_duplicates$scala_code)),
  add_num("Removed duplicate projects stars", sum(removed_duplicates$gh_stars)),
  add_num("Removed duplicate projects size", sum(removed_duplicates$size_repo), formatter=format_size)
) %>% my_datatable()
```

## Pipeline

In stage 2 each project goes through the following phases:

1. **Metadata extraction.**
   This runs `sbt clean metadata` which is our SBT [plugin](https://github.com/PRL-PRG/scala-implicits-analysis/tree/oopsla19/sbt-plugins) that outputs relevant SBT configuration into a number of CSV files.
   Even though we are only interested in metadata, getting the full project dependenct classpath including inter-project dependencies will trigger a new compilation round.
   It has been suggested that there is a workaround for this (cf. [stackoverflow](https://stackoverflow.com/questions/53816695/how-to-get-dependencyclasspath-in-sbt-build-without-triggering-compilation)), but unfortunately that has side effects, namely missing source directories.

2. **Semanticdb generation.**
   This runs `sbt semanticdb` command which configures the projects scalac options to include the semanticdb [plugin](https://scalameta.org/docs/semanticdb/guide.html#scalac-compiler-plugin) with the option to output synthetics, i.e. pieces of AST added by the scala compiler which among other things are implicits.
  
3. **Implicits extraction.**
   Finally, we run our [tool](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ExtractImplicits.scala) that takes semanticdb and project metadata and produce a [model](https://github.com/PRL-PRG/scala-implicits-analysis/blob/master/libs/model/src/main/protobuf/model.proto) of implicit declarations and call sites.
   The final model is stored in a Google protocol buffer format and the individual projects' models are merged into ``r GLOBAL_IMPLICITS`` file.

### Phase overview

Since we are working with real-world projects it is possible that not all of them will make it through all the phases.
The following table shows how many projects (Scala code and GitHub stars) do we loose in each step.

```{r}
corpus_shrinking <- tibble(phase=character(0), projects=integer(0), sloc=integer(0), stars=integer(0), size=integer(0))
add_phase <- function(phase, df, sloc="metadata_scala_code", stars="gh_stars", size="size_repo") {
  corpus_shrinking <<- add_row(
    corpus_shrinking, 
    phase=phase, 
    projects=nrow(df),
    sloc=ifelse(nrow(df) > 0, sum(df[, sloc], na.rm=T), 0),
    stars=ifelse(nrow(df) > 0, sum(df[, stars], na.rm=T), 0), 
    size=format_size(ifelse(nrow(df) > 0, sum(df[, size], na.rm=T), 0))
  )
}

add_phase("All projects", stage3_corpus)
add_phase("Metadata extraction",     filter(stage3_corpus, metadata_exit_code==0))
add_phase("Semanticdb generation",   filter(stage3_corpus, semanticdb_exit_code==0))
add_phase("Implicits extraction",    filter(stage3_corpus, implicits_exit_code==0))

corpus_shrinking %>% 
  my_datatable(colnames = c("Phase", "Number of projects", "Scala code", "GitHub Stars", "Project size"))
```

Connecting that with the data from stage 1:

```{r}
corpus_shrinking <- tibble(phase=character(0), projects=integer(0), sloc=integer(0), stars=integer(0), size=integer(0))

add_phase("Cloned projects", stage1_corpus, "scala_code")
add_phase("Compatible SBT projects", filter(stage1_corpus, compatible), "scala_code")
add_phase("Removed duplicate projects", anti_join(filter(stage1_corpus, compatible), stage3_corpus, by="project_id"), "scala_code")
add_phase("Without duplicates", stage3_corpus, "scala_code")
add_phase("Metadata extraction", filter(stage3_corpus, metadata_exit_code==0), size="size")
add_phase("Semanticdb generation", filter(stage3_corpus, semanticdb_exit_code==0), size="size")
add_phase("Implicits extraction", filter(stage3_corpus, implicits_exit_code==0), size="size")

corpus_shrinking %>% 
  my_datatable(colnames = c("Phase", "Number of projects", "Scala code", "GitHub Stars", "Project size"))
```

### Errors

The following analysis shall help to identify the error that occur in the different phases.

This table shows the summary of exit codes in the different phases:

```{r}
phases <- c("metadata", "compile", "semanticdb", "implicits")
phases_data <- list(
  select(stage3_corpus, project_id, exit_code=metadata_exit_code),
  select(stage3_corpus, project_id, exit_code=compile_exit_code),
  select(stage3_corpus, project_id, exit_code=semanticdb_exit_code),
  select(stage3_corpus, project_id, exit_code=implicits_exit_code)
)
status <- map2_dfr(phases, phases_data, ~phase_status(.x, .y)) %>% mutate_at(vars(-phase), function(x) coalesce(x, 0))
status %>% my_datatable()
```

#### Failed metadata, but has semanticdb

These are errors should be investigated closely, since extracting metadata should in general have less problems that generating semanticdb.
However, with SBT no one really knows.

```{r}
sdb_no_metadata <- filter(stage3_corpus, metadata_exit_code != 0, semanticdb_exit_code == 0) %>%
  select(project_id, metadata_exit_code, metadata_failure, metadata_failure_detail, metadata_duration, metadata_scala_code, gh_stars)
```

```{r}
sdb_no_metadata %>%
  count(metadata_failure) %>% 
  my_datatable()
```

```{r}
sdb_no_metadata %>% 
  my_datatable()
```

### Metadata and semanticdb errors

This is to guess what has happened.
Execution of each phase is stored in a log file.
The log files are stored in `<project_directory>/_analysis_/<phase>.log` where phase is one if (`compile`, `metadata`, `semanticdb`, `implcits`).
We query these log files for a number of regular expressions that identify common failures.
They are decribed in the `[guess_failure_cause](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/scripts/inc/functions.R#L181)` function.

```{r}
failed_projects <- filter(
  stage3_corpus, 
  metadata_exit_code == 1 | 
    (metadata_exit_code == 0 & semanticdb_exit_code == 1)
) %>%
  mutate(
    phase=case_when(
      metadata_exit_code == 1 ~ "metadata",
      semanticdb_exit_code == 1 ~ "semanticdb",
      TRUE ~ as.character(NA)
    ),
    cause=if_else(metadata_exit_code == 1, metadata_failure, semanticdb_failure),
    cause_detail=if_else(metadata_exit_code == 1, metadata_failure_detail, semanticdb_failure_detail),
    duration=if_else(phase=="metadata", metadata_duration, semanticdb_duration)
  ) %>%
  select(project_id, phase, cause, cause_detail, metadata_scala_code, gh_stars)
```

Summarized by exceptions:

```{r}
count(failed_projects, cause) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

```{r}
make_stats(
  add_nrow("Projects failed to build", filter(stage3_corpus, implicits_exit_code!=0 | is.na(metadata_scala_code))),
  add_nrow("Projects missing dependencies", filter(failed_projects, cause=="missing-dependencies")),
  add_nrow("Projects with compile error", filter(failed_projects, cause=="compilation-failed")),
  add_nrow("Projects with broken build", filter(failed_projects, cause=="project-loading-failed")),
  add_nrow("Projects with empty build", filter(stage3_corpus, implicits_exit_code==0, is.na(metadata_scala_code))),
  add_nrow("Projects missing Scala JS", filter(failed_projects, cause=="missing-dependencies", str_detect(cause_detail, "scalajs"))),
  add_nrow("Projects missing Snapshot Dependencies", filter(failed_projects, cause=="missing-dependencies", str_detect(cause_detail, "SNAPSHOT")))
) %>% my_datatable()
```


#### Missing dependencies

Missing dependencies is a common failure.
This section gives an overview which dependencies are missing to help to indentify if there are some patterns.
The `guess_failure_cause` function only considers the first missing dependency.

```{r}
count(filter(failed_projects, cause=="missing-dependencies"), cause_detail) %>% arrange(desc(n)) %>% my_datatable(colnames=c("Dependency", "Count"))
```

Notes:
- The `scalajs` is possibly missing because it has been removed due to some security vulnerabilities is some particular version.

#### List of Java errors

The list of JVM errors reported during any of the phases.
This helps us to identify if there are some patterns.

```{r}
filter(failed_projects, cause=="java-error") %>%
  mutate(
    log=make_corpus_link(path(project_id, "_analysis_", str_c(phase, ".log")))
  ) %>%
  select(-phase, -cause) %>%
  select(project_id, log, everything()) %>%
  my_datatable(escape=FALSE)
```


#### List of unknown problems

This is just to see of peraps there is something that could be done about it.
For our experience, these are simply broken builds.

```{r}
filter(failed_projects, cause=="unknown") %>%
  mutate(
    log=make_corpus_link(path(project_id, "_analysis_", str_c(phase, ".log")))
  ) %>%
  select(-phase, -cause) %>%
  select(project_id, log, everything()) %>%
  my_datatable(escape=FALSE)
```

## Missing Semanticdb

In some cases, the semanticdb would run, but not generate any output.
This is just a safety measure to list projects for which the pipeline reports a successful semanticdb generation, yet they need a manual inspection since no output has been generated.

```{r}
filter(corpus, semanticdb_exit_code==0, is.na(semanticdb_files) | semanticdb_files==0) %>%
  mutate(path=make_corpus_link(project_id)) %>%
  select(project_id, path, metadata_exit_code, scala_version, commit_count, gh_stars, metadata_scala_code) %>%
  my_datatable(escape=FALSE)
```

## Errors in implicit extraction

The final phase runs the [implicit extractor](https://github.com/PRL-PRG/scala-implicits-analysis/blob/oopsla19/libs/tools/src/main/scala/cz/cvut/fit/prl/scala/implicits/tools/ExtractImplicits.scala).
The extractor takes the generated semanticdb files together with the extracted metadata and build a [model](https://github.com/PRL-PRG/scala-implicits-analysis/blob/master/libs/model/src/main/protobuf/model.proto) of implicits.
Not all implcits that we find the semanticdb can be resolved and stored in our model.
There is a number of issues that can appear, but the main ones are:
- missing symbol - the implicit is referencing a symbol that cannot be found in neither the semanticdb nor the class path extracted from SBT
- unsupported type - semanticdb defines 14 different [Scala types](https://github.com/scalameta/scalameta/blob/master/semanticdb/semanticdb3/semanticdb3.md#scala-type). We do not support structural, dependent and existential types.
- missing term - the implicit call sites are injected by compiler. These are represented in semanticdb as AST [nodes](https://github.com/scalameta/scalameta/blob/master/semanticdb/semanticdb3/semanticdb3.md#tree) which are different from Scala AST. Our tool tries to map terms from one to the other, but it might not be possible every time. 

### Failures

This lists failures encountered when trying to extract implicits from semanticdb.
A failure is when the running the extractor did not terminate normally.

```{r}
filter(corpus, !is.na(implicit_failure)) %>%
  select(project_id, implicit_failure, metadata_scala_code, gh_stars) %>%
  my_datatable()
```

Notes:
- The `ZipException: error in opening zip file` means that it could not open a a dependency jar file.

### Errors

When extracting implicit declarations and call sites, there can be a number of problems.
Each of the gets logged into an ``r IMPLICITS_EXCEPTIONS`` files.
The following is their classification based on a number of regular expressions.

```{r load implicit errors}
exceptions <- read_data(IMPLICIT_EXCEPTIOSN_F)
```

```{r}
classified_exceptions <- 
  mutate(
    exceptions,
    class=case_when(
      exception == "SymbolNotFoundException" & str_detect(message, "local\\d+") ~ "missing-local-symbol",
      exception == "SymbolNotFoundException" & str_detect(message, "symbol: local\\d+") ~ "missing-local-symbol",
      exception == "SymbolNotFoundException" & str_detect(message, "at Range\\(\\d+,\\d+,\\d+,\\d+\\)") ~ "missing-symbol-at-range",
      exception == "SymbolNotFoundException" ~ "missing-symbol-other",
      exception == "LoadingMetadataException" & str_detect(message, "No module found") & str_detect(message, "multi-jvm") ~ "missing-module-multijvm",
      exception == "LoadingMetadataException" & str_detect(message, "No module found") ~ "missing-module",
      exception == "LoadingMetadataException" ~ "metadata-loading",
      exception == "NotImplementedError" ~ "not-implemented",
      exception == "UnexpectedElementException" ~ "unexpected-element",
      exception == "UnsupportedElementException" ~ "unsupported-element",
      exception == "UnExtractableCallSiteException" & cause == "SymbolNotFoundException" ~ "unextractable-callsite-missing-term",
      exception == "UnExtractableCallSiteException" & cause == "FunctionNotFoundException" ~ "unextractable-callsite-missing-function",
      exception == "UnExtractableCallSiteException" ~ "unextractable-callsite-other",
      exception == "ImplicitArgumentNotFoundException" ~ "missing-implicit-arguments",
      exception == "Exception" & str_detect(message, "^Invalid call site argument") ~ "invalid-declaration",
      TRUE ~ "unclassified"
    )
  )
```

#### Per project summary

```{r}
count(classified_exceptions, project_id) %>% 
  left_join(select(corpus, project_id, metadata_scala_code, gh_stars), by="project_id") %>%
  arrange(desc(n)) %>% 
  my_datatable() 
```

#### Per error class summary

```{r}
count(classified_exceptions, class) %>% arrange(desc(n)) %>% my_datatable()
```

#### Per project and error class summary

```{r}
count(classified_exceptions, project_id, class) %>% arrange(desc(n)) %>% my_datatable()
```

#### Missing symbols

Missing local symbols (symbols defined just a block - we do not need to worry about them).

```{r}
filter(classified_exceptions, class=="missing-local-symbol") %>% 
  count(project_id) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

Missing symbols from a range when aligning the two ASTs.

```{r}
filter(classified_exceptions, class=="missing-symbol-at-range") %>% 
  count(project_id) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

All other missing symbols.

```{r}
filter(classified_exceptions, class=="missing-symbol-other") %>% 
  count(project_id) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

The following is a list of the missing symbols.
This might help us to identify is there are some patterns.

```{r}
filter(classified_exceptions, class=="missing-symbol-other") %>% 
  transmute(project_id, symbol=str_replace_all(message, ".*symbol: (.*)$", "\\1")) %>%
  count(project_id, symbol) %>% 
  arrange(desc(n)) %>% 
  my_datatable()
```

#### Unclassified

These are all the other errors that occured

```{r}
filter(classified_exceptions, class=="unclassified") %>%
  select(project_id, module_id, class, everything()) %>%
  my_datatable()
```

### Callsites and implicit callsites

A quick overview of the implicit call sites and implicit declarations.

```{r}
filter(corpus, implicits_exit_code==0, metadata_scala_code > 100) %>%
  mutate(
    outlier=is_outlier(callsites)|is_outlier(implicit_callsites),
    label=if_else(outlier, str_glue("{project_id}"), as.character(NA))
  ) %>%
  ggplot(
    aes(
      x=callsites, 
      y=implicit_callsites, 
      label=label, 
      color=if_else(scaladex, "Library", "Application")
    )
  ) +
    geom_point(size=.5) +
    geom_text(size=3, check_overlap = T, vjust=1.5, na.rm = TRUE) + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) +
    geom_vline(aes(xintercept=mean(callsites)), linetype=2, color="black", size=.2) + 
    geom_hline(aes(yintercept=mean(implicit_callsites)), linetype=2, color="black", size=.2) +
    labs(
      title="Ratio of regular call sites and implicit call sites",
      x="Number of callsites (log)", 
      y="Number of implicit callsites (log)", 
      color="Project type"
    )
```

```{r}
filter(corpus, implicits_exit_code==0, metadata_scala_code>0) %>%
  mutate(
    outlier=is_outlier(metadata_scala_code)|is_outlier(implicit_local_declarations),
    label=if_else(outlier, str_glue("{project_id}"), as.character(NA))
  ) %>%
  ggplot(
    aes(
      x=metadata_scala_code, 
      y=implicit_local_declarations, 
      label=label, 
      color=if_else(scaladex, "Library", "Application")
    )
  ) +
    geom_point(size=.5) +
    geom_text(size=3, check_overlap = T, vjust=1.5, na.rm = TRUE) + 
    scale_x_log10(labels = scales::comma) + 
    scale_y_log10(labels = scales::comma) +
    geom_vline(aes(xintercept=mean(metadata_scala_code)), linetype=2, color="black", size=.2) + 
    geom_hline(aes(yintercept=mean(implicit_local_declarations)), linetype=2, color="black", size=.2) +
    labs(
      title="Ratio of regular source code size and number of implicit decalarations",
      x="Source lines of code (log)", 
      y="Number of local declarations (log)", 
      color="Project type"
    )
```

### Time of the successfull projects

Finally, we report the time each phase took for the successful projects.
This gives a hint about how long rebuilding the repository of passing projects will take.

```{r}
make_stats(
  add_num("Metadata extraction time", corpus$metadata_duration),
  add_num("Compile time", corpus$compile_duration),
  add_num("Semanticdb extraction time", corpus$semanticdb_duration),
  add_num("Implicits extraction time", corpus$implicits_duration)
) %>%
  my_datatable()
```
