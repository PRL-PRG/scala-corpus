# -*- mode: makefile -*-

# the location of this makefile
base_dir := $(dir $(abspath $(shell readlink $(lastword $(MAKEFILE_LIST)))))
this_makefile := $(lastword $(MAKEFILE_LIST))

include $(base_dir)/Makevars

LOG_DIR_BASE := logs
LOG_DIR := $(LOG_DIR_BASE)/$(shell date +"%Y%m%d-%H%M%S")
LOG_DIR_LATEST := $(LOG_DIR_BASE)/latest
CORPUS := $(shell basename $$(pwd))

# a file controlling the number of parallel tasks it can be updated while the
# task is run, but gets reset before a task is run
JOBS_FILE := jobsfile.txt

REDO ?= 0

# --------------------------------------------------------------------------------

parallel := $(MAKE) -f $(this_makefile) parallel

bootstrap :=

.PHONY: \
	parallel \
	clean \
	clean-compile \
	clean-dejavu \
	clean-implicits \
	clean-metadata \
	clean-projects \
	clean-repo-metadata \
	clean-sbt \
	clean-semanticdb \
	reset \
	reset-all \
	download-projects \
	patch-downloaded-projects \
	repo-metadata \
	filter-all-projects \
	filter-sbt-projects \
	filter-final-repos \
	fetch-github-info \
	scaladex \
	dejavu \
	compile \
	metadata \
	semanticdb \
	implicits \
	corpus-stage1 \
	corpus-stage3 \
	export-implicits \
	report

all: download-projects \
	stage1 \
	stage2 \
	stage3 \
	report

$(LOG_DIR):
	@mkdir -p $(LOG_DIR)
	@rm -f $(LOG_DIR_LATEST)
	@ln -s $(notdir $(LOG_DIR)) $(LOG_DIR_LATEST)

stage1:	repo-metadata \
	filter-sbt-projects \
	fetch-github-info \
	filter-all-projects \
	dejavu \
	scaladex \
	corpus-stage1 \
	filter-final-projects

stage2: compile \
	metadata \
	semanticdb

stage3: implicits \
	corpus-stage3 \
	export-implicits \
	report

parallel:
	-mkdir -p $(LOG_DIR)
	@echo $(N_JOBS) > jobsfile.txt
	@echo ">> Running parallel task $(TASK) (REDO=$(REDO)) with logs in $(LOG_DIR) using $(PROJECTS_FILE)..."
	cp $(PROJECTS_FILE) $(LOG_DIR)/projects.txt
	touch "$(LOG_DIR)/$(TASK)"
	-$(parallel_base) \
      --jobs $(JOBS_FILE) \
      -a "$(PROJECTS_FILE)" \
      --files \
      --bar \
      --tagstring "$(TASK) - {}:" \
      --result "$(PROJECTS_DIR)/{1}/$(ANALYSIS_DIR)/parallel/$(TASK)" \
      --joblog "$(LOG_DIR)/$(TASK)-parallel.log" \
      --timeout $(TIMEOUT) \
      make $(MFLAGS) -C "$(PROJECTS_DIR)/{1}" -f $(base_dir)/Makefile.project $(TASK) REDO=$(REDO)

clean:
	-$(MAKE) -f $(this_makefile) parallel TASK=$@
	-$(MAKE) -f $(this_makefile) clean-dejavu
	-rm -fr $(LOG_DIR_BASE) $(JOBSFILE)
	-rm -f $(GLOBAL_REPO_METADATA)
	-rm -f $(GLOBAL_REPO_SLOC)
	-rm -fr $(SBT_PROJECTS_FILE) $(PROJECTS_DIR) $(PROJECTS_FILE)
	-rm -f $(PROJECTS_GITHUB_INFO) $(SCALADEX) $(JOBS_FILE) $(ALL_PROJECTS_ORIG_FILE)
	-rm -f $(GLOBAL_METADATA_STATUS) $(GLOBAL_METADATA_MODULES) $(GLOBAL_METADATA_SOURCEPATHS) $(GLOBAL_METADATA_DEPENDENCIES)
	-rm -f $(GLOBAL_COMPILE_STATUS)
	-rm -f $(GLOBAL_SEMANTICDB_STATUS) $(GLOBAL_SEMANTICDB_MERGED_STATS_FILE)
	-rm -f $(GLOBAL_IMPLICITS_STATUS) $(GLOBAL_IMPLICITS_STATS) $(GLOBAL_IMPLICITS_EXCEPTIONS) $(GLOBAL_IMPLICITS)
	-rm -f $(CORPUS_STAGE1) $(CORPUS_STAGE3)
	-rm -f $(CORPUS_ANALYSIS_HTML) $(IMPLICIT_CALLSITES) $(IMPLICIT_DECLARATIONS)
	-rm -f $(REPORTS)
	-rm -f ${EXPORTED_IMPLICIT_FILES:.csv=.fst.gz}
	-rm -f ${EXPORTED_IMPLICIT_FILES:.csv=.fst}
	-rm -f $(EXPORTED_IMPLICIT_FILES)

clean-compile:
	$(MAKE) -f $(this_makefile) parallel TASK=$@
	-rm -f $(GLOBAL_COMPILE_STATUS)

clean-dejavu:
	-rm -fr $(DEJAVU_HOME) $(DEJAVU_FILES_HASH) $(DEJAVU_DUPLICATION)

clean-implicits:
	$(MAKE) -f $(this_makefile) parallel TASK=$@
	-rm -f $(GLOBAL_IMPLICITS_STATUS) \
         $(GLOBAL_IMPLICITS_STATS) \
         $(GLOBAL_IMPLICITS_EXCEPTIONS) \
         $(GLOBAL_IMPLICITS) \
         $(GLOBAL_IMPLICITS_INDEX_EXCEPTIONS)

clean-metadata:
	$(MAKE) -f $(this_makefile) parallel TASK=$@
	-rm -f $(GLOBAL_METADATA_STATUS) $(GLOBAL_METADATA_MODULES) $(GLOBAL_METADATA_SOURCEPATHS) $(GLOBAL_METADATA_DEPENDENCIES)

clean-projects:
	-rm -fr $(PROJECTS_FILE) $(PROJECTS_DIR)

clean-repo-metadata:
	$(MAKE) -f $(this_makefile) parallel TASK=$@
	-rm -f $(GLOBAL_REPO_METADATA) $(GLOBAL_REPO_SLOC)

clean-sbt:
	$(MAKE) -f $(this_makefile) parallel TASK=$@

clean-semanticdb:
	$(MAKE) -f $(this_makefile) parallel TASK=$@
	-rm -f $(GLOBAL_SEMANTICDB_STATUS) $(GLOBAL_SEMANTICDB_MERGED_STATS_FILE)

reset: $(bootstrap)
	$(parallel) TASK=$@ PROJECTS_FILE=$(ALL_PROJECTS_FILE) PROJECTS_DIR=$(ALL_PROJECTS_DIR)

reset-all: $(bootstrap)
	$(parallel) TASK=$@ PROJECTS_FILE=$(ALL_PROJECTS_FILE) PROJECTS_DIR=$(ALL_PROJECTS_DIR)

dejavu: $(SBT_PROJECTS_FILE) $(ALL_PROJECTS_DIR)
	-rm -fr $(DEJAVU_HOME)
	mkdir -p $(DEJAVU_HOME)

	-rm -fr $(DEJAVU_DOWNLOAD)
	mkdir -p $(DEJAVU_DOWNLOAD)

	$(parallel_base) --bar -j1 -a $(SBT_PROJECTS_FILE) ln -sfT '$$(pwd)/$(ALL_PROJECTS_DIR)/{1}' '$$(pwd)/$(DEJAVU_DOWNLOAD)/{#}'

	$(SCRIPTS_DIR)/generate-dejavu-input.R $(SBT_PROJECTS_FILE) $(DEJAVU_INPUT)
	sed -i 's/"""/"/g'  $(DEJAVU_INPUT)

	cd $(DEJAVU_HOME) && \
      $(SCRIPTS_DIR)/tools/js-tokenizer/build/tokenizer Scala $(notdir $(DEJAVU_INPUT)) 1 0 .; \
      echo "Done tokenizing";

	mv $(DEJAVU_HOME)/files_0.csv $(DEJAVU_HOME)/files.csv
	mv $(DEJAVU_HOME)/stats_0.csv $(DEJAVU_HOME)/stats.csv
	mv $(DEJAVU_HOME)/summary_0.txt $(DEJAVU_HOME)/summary.txt
	mv $(DEJAVU_HOME)/projects_0.csv $(DEJAVU_HOME)/projects.csv

	cd $(SCRIPTS_DIR)/tools/sccpreprocessor/src && \
      java SccPreprocessor h2i $(CURDIR)/$(DEJAVU_HOME)

	$(SCRIPTS_DIR)/merge-dejavu-files-hash.R $(DEJAVU_FILES_HASH) $(DEJAVU_DUPLICATION)

download-projects: $(ALL_PROJECTS_FILE)
	-mkdir -p $(ALL_PROJECTS_DIR)
	-cat $(ALL_PROJECTS_FILE) | sed 's|\(.*\)--\(.*\)|\1,\2|g' | \
        $(parallel_base) --timeout 30m -C, --bar -j8 $(SCRIPTS_DIR)/download-project.sh 'https://github.com/{1}/{2}' '$(ALL_PROJECTS_DIR)/{1}--{2}'
	$(MAKE) -f $(this_makefile) patch-downloaded-projects

filter-all-projects: $(ALL_PROJECTS_FILE) $(PROJECTS_GITHUB_INFO)
	$(SCRIPTS_DIR)/filter-all-projects.R

filter-sbt-projects: $(GLOBAL_REPO_METADATA)
	$(SCRIPTS_DIR)/filter-sbt-projects.R

filter-final-projects: $(PROJECTS_FILE)
	rm -fr $(PROJECTS_DIR)
	mkdir -p $(PROJECTS_DIR)
	$(parallel_base) --bar -j1 -a $(PROJECTS_FILE) ln -s '../$(ALL_PROJECTS_DIR)/{1}' '$(PROJECTS_DIR)'

fetch-github-info: $(SBT_PROJECTS_FILE)
	if [ -f $(PROJECTS_GITHUB_INFO).pinned ]; then \
    cp $(PROJECTS_GITHUB_INFO).pinned $(PROJECTS_GITHUB_INFO); \
  else \
    $(SCRIPTS_DIR)/fetch-github-info.R $(SBT_PROJECTS_FILE) $(PROJECTS_GITHUB_INFO); \
    cp $(PROJECTS_GITHUB_INFO) $(PROJECTS_GITHUB_INFO).pinned; \
  fi

patch-downloaded-projects:
	[ -f $(ALL_PROJECTS_PATCH) ] && $(SCRIPTS_DIR)/patch-downloaded-projects.R $(ALL_PROJECTS_PATCH) $(ALL_PROJECTS_DIR) || /bin/true

repo-metadata: $(ALL_PROJECTS_FILE) $(ALL_PROJECTS_DIR)
ifneq ($(REDO), -1)
	$(parallel) TASK=repo-metadata PROJECTS_FILE=$(ALL_PROJECTS_FILE) PROJECTS_DIR=$(ALL_PROJECTS_DIR)
endif
	$(SCRIPTS_DIR)/merge-csvs.R $(ALL_PROJECTS_FILE) $(ALL_PROJECTS_DIR) $(REPO_METADATA) "ccddiciiii" $(GLOBAL_REPO_METADATA)
	$(SCRIPTS_DIR)/merge-csvs.R $(ALL_PROJECTS_FILE) $(ALL_PROJECTS_DIR) $(REPO_SLOC) "iciii" $(GLOBAL_REPO_SLOC)

scaladex:
	if [ -f $(SCALADEX).pinned ]; then \
      cp -f $(SCALADEX).pinned $(SCALADEX); \
    else \
      $(SCRIPTS_DIR)/scaladex.R $(SCALADEX).pinned; \
      cp -f $(SCALADEX).pinned $(SCALADEX); \
    fi

metadata: $(PROJECTS_DIR) $(PROJECTS_FILE)
ifneq ($(REDO), -1)
	$(parallel) TASK=metadata REDO=$(REDO)
endif

	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(METADATA_STATUS) "ii" $(GLOBAL_METADATA_STATUS)
	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(METADATA_MODULES) "cccccccccccc" $(GLOBAL_METADATA_MODULES)
	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(METADATA_SOURCEPATHS) "ccclciciii" $(GLOBAL_METADATA_SOURCEPATHS)
	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(METADATA_DEPENDENCIES) "cccccccl" $(GLOBAL_METADATA_DEPENDENCIES)

compile: $(PROJECTS_DIR) $(PROJECTS_FILE)
ifneq ($(REDO), -1)
	$(parallel) TASK=compile REDO=$(REDO)
endif

	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(COMPILE_STATUS) "iii" $(GLOBAL_COMPILE_STATUS)

semanticdb: $(PROJECTS_FILE) $(PROJECTS_DIR)
ifneq ($(REDO), -1)
	$(parallel) TASK=semanticdb REDO=$(REDO)
endif

	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(SEMANTICDB_STATUS) "iii" $(GLOBAL_SEMANTICDB_STATUS)
	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(SEMANTICDB_MERGED_STATS_FILE) "iiii" $(GLOBAL_SEMANTICDB_MERGED_STATS_FILE)

implicits: $(PROJECTS_FILE) $(PROJECTS_DIR)
ifneq ($(REDO), -1)
	$(parallel) TASK=implicits REDO=$(REDO)
endif

	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(IMPLICITS_STATUS) "ii" $(GLOBAL_IMPLICITS_STATUS)
	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(IMPLICITS_STATS) "cciiiiiii" $(GLOBAL_IMPLICITS_STATS)
	$(SCRIPTS_DIR)/merge-csvs.R $(PROJECTS_FILE) $(PROJECTS_DIR) $(IMPLICITS_EXCEPTIONS) "cccccccc" $(GLOBAL_IMPLICITS_EXCEPTIONS)
	$(AMM) $(SCRIPTS_DIR)/merge-implicits.sc --projectFile $(PROJECTS_FILE) --projectDir $(PROJECTS_DIR)
	$(SCRIPTS_DIR)/quick-summary.R

corpus-stage1: $(GLOBAL_REPO_METADATA) \
  $(GLOBAL_REPO_SLOC) \
  $(SCALADEX) \
  $(PROJECTS_GITHUB_INFO) \
  $(DEJAVU_DUPLICATION)

	$(SCRIPTS_DIR)/corpus-stage1.R

corpus-stage3: $(GLOBAL_COMPILE_STATUS) \
  $(GLOBAL_METADATA_STATUS) \
  $(GLOBAL_SEMANTICDB_STATUS) \
  $(GLOBAL_SEMANTICDB_MERGED_STATS_FILE) \
  $(GLOBAL_IMPLICITS_STATUS) \
  $(GLOBAL_IMPLICITS_STATS) \
  $(GLOBAL_IMPLICITS_EXCEPTIONS) \
  $(CORPUS-STAGE1)

	$(SCRIPTS_DIR)/corpus-stage3.R

export-implicits: $(GLOBAL_IMPLICITS)
	$(AMM) $(SCRIPTS_DIR)/export-implicits.sc $(GLOBAL_IMPLICITS)
	$(parallel_base) --bar $(SCRIPTS_DIR)/csv-to-fst.R ::: $(EXPORTED_IMPLICIT_FILES)

%.html:
	Rscript -e "rmarkdown::render('$(SCRIPTS_DIR)/analysis/${@:html=Rmd}', output_dir='$(CURDIR)', params=list(base_dir='$(CURDIR)', lib_dir='../inc'))"

report: $(REPORTS)
